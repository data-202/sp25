---
title: "Case Study 2, Part 1: The True Size of Africa"
subtitle: "DATA 202 - Alexander"
format: 
  html:
    self-contained: true
    self-contained-math: true
editor: visual
---

In Case Study 2, we will explore the social politics of maps and globally oriented data to help us make sense of what we mean by a "population." The case study will integrate a series of new packages, functions, and code to support our explorations.

There are two parts to this case study, this is part 1.

## Learning Objectives

In this case study component, you will be introduced to the `dplyr` package, which is one of the many packages in the [`tidyverse`](https://www.tidyverse.org/). The `tidyverse` is a set of packages that will be used for cleaning and organizing data.

------------------------------------------------------------------------

## Learning Activities

By the end of this case study you will be able to:

1.  Install and/or update R packages
2.  Assign data frames to different names for efficient exploration
3.  Generate a set of outputs using the [`dplyr`](https://dplyr.tidyverse.org/) package
4.  Overwrite a data frame while using the [pipe operator](https://style.tidyverse.org/pipes.html)
5.  Produce simple plots using data located in an `R` package

## Developing a workflow

Coding workflows are an essential component of project completion.

When analyzing data, it is important to understand the possible intersections between the `context`, `content`, and `code`. The best way to explore these relationships is by conducting a literature review. Reading about what others have done is more valuable than starting a workflow prematurely.

Time may be used inefficiently and clear but standard outputs provide narratives that can likely be confirmed by or support what is already in the research literature. Without an understanding of these connections, analytic outputs may do less to move our understanding of issues forward.

This case study will help you explore and create your own workflow. The goal of a coding workflow is not to simply `copy` and `paste` arguments that you find. Instead, you want to develop clear pathways to identifying solutions as you work with your data.

The topics in case study 2 cover one way to approach a new data set. In this case study, you'll cover how to load data from a package, generate a set of outputs using small code chunks, and produce and submit a few simple plots.

------------------------------------------------------------------------

# Part 0: Pre-case study tasks

-   Check your working directory

-   Start a new R Script

-   Write a preamble

-   Install and/or update packages and load libraries

## Task 0.1: Check your working directory

In your console, type in the following code to ensure you are in the desired directory:

```{r}
#| echo: true
#| output: false
#| warning: false
getwd()
```

If you are not in the desired directory, you can change your directory using the associated path. This path should be the same as the project folder that you plan to work out of and set up in lecture five.

```{r}
#| echo: true
#| output: false
#| warning: false
# insert your desired path in the parenthesis and remove the #
# setwd("/your/working/directory/goes/here") 
```

You can add a new sub-folder manually or under the **Files** tab in the RStudio IDE.

## Task 0.2: Start a new RMarkdown file

Once you have confirmed that you are in the correct directory, start a new RMarkdown file (.Rmd) and write your preamble.

```{r, eval=F}

---
title: "Case Study 2"
author: "Your Full Name"
date: "2024-09-09"
output:
  pdf_document: default
  html_document:
    theme: flatly
editor_options:
  markdown:
  wrap: sentence
 ---

```

## Task 0.3: Write setup code chunks

```{r}
#| echo: true
#| output: false
#| warning: false

# ```{r, eval=F}
# install.packages("devtools")
# library(devtools)
```

## Task 0.4: Packages and libraries

```{r}
#| echo: true
#| output: false
#| warning: false

# install package
# install.packages("tidyverse", repos = "http://cran.us.r-project.org")
# install.packages("remotes", repos = "http://cran.us.r-project.org")
 
# load the necessary libraries
library(tidyverse) #collection of R packages designed for data science
library(dplyr)
library(remotes)
```

The `dplyr` package supports data analyst with efficient data manipulation. As a part of the `tidyverse` package, the functions included in `dplyr` we loaded earlier will help you generate efficient workflows. Though, in reality, most analysts transition between classic code found widely on the internet and the more recent `dplyr` commands.

The `remotes` library will allow you to remotely install `critstats` data.

------------------------------------------------------------------------

# Part 1: The true size of Africa

In this part of the case study, you will complete the following tasks:

-   Explore notes on the social politics of maps

-   Examine the `true_size` data in the `critstats` package

-   Construct a response to the issue of misrepresentation in maps

![The world's continents. Image from Encyclopedia Britannica.](../img/lab1-continents.jpg){width="50%"}

## Task 1.1: Explore notes on the social politics of maps

-   [What is a map?](https://education.nationalgeographic.org/resource/map/#:~:text=Maps%20present%20information%20about%20the,features%2C%20and%20distances%20between%20places) This *National Geographic* education resource presents a clear overview of maps, geography, and Geographic Information Systems (GIS).

-   [What's the real size of Africa?](https://www.cnn.com/2016/08/18/africa/real-size-of-africa/index.html) is a CNN Africa Marketplace article that examines the Western foundations of maps and representations of the African continent.

-   [Vaughan (2018)](https://www.jstor.org/stable/j.ctv550dcj) is an open access publication on the *spatial dimensions of social cartography*. The text contains valuable information about how maps have been used to understand health and human development issues, such as poverty, disease, housing, and the like. The text also contains notes on race and nationality, crime and disorder, and a host of references for further reading.

-   [Manson & Matson (2017)](https://open.lib.umn.edu/mapping/chapter/1-maps-society-and-technology/) present an overview of society and mapping with new technological tools. While doing so, the authors provide a history of maps and examine the basic social elements of maps, the technical elements of maps, and how maps have been integrated into liberal arts education.

-   [Crampton (2015)](https://press.uchicago.edu/books/HOC/HOC_V6/HOC_VOLUME6_R.pdf) writes on *Maps and the Social Construction of Race* in a larger volume on maps produced by the University of Chicago Press.

-   [Alderman & Inwood (2021)](https://theconversation.com/how-black-cartographers-put-racism-on-the-map-of-america-155081) describe how Black cartographers use maps to examine issues of racial inequality. The authors provide a more focused discussion on the social politics of maps, as opposed to a more general overview of their functions.

-   [Can maps be racist?](https://sociologyinfocus.com/your-map-is-racist-and-heres-how-2/) Palmer (2014) provides some context to understand the technical aspects of maps as they relate to our social construction of the global world. In this review, the author situates the common functions of maps onto the social dimensions while attending to the particular periods of the development and construction of global maps; thus integrating the political dimension of knowledge creation via map making.

    -- [Britton (2021)](https://areomagazine.com/2021/03/08/in-defence-of-the-mercator-projection-the-non-racism-of-maps/) in a blog post on the "non-racism of maps" offers a very different perspective on the Mercator projection. The author focuses on ideology and science in modern society. He argues that the original purpose of maps does not make them racist.

-   [How maps distort our perception of the world](https://the-ard.com/2023/06/09/the-mercator-projection-and-how-maps-distort-the-world/) is a short and focused resource written by Lee (2023) on the Anti-Racism Daily site. The author focuses on the social politics of perception.

![The world's continents. Image from https://www.visualcapitalist.com/map-true-size-of-africa/](../img/lab1-truesize.jpg){width="75%"}

## Task 1.2: Load the `true_size` data

### Task 1.2.1: Install the `critstats` package

To begin, we will install and/or update the installation of `critstats`.

```{r}
#| echo: true
#| output: false
#| warning: false
# use the remote install function to call in your data
remotes::install_github("professornaite/critstats", force=TRUE)

# load the `critstats` library
library(critstats)

# update the `critstats` package if needed
# update.packages("critstats")
```

### Task 1.2.2: Call the `true_size` data

```{r}
#| output: false
critstats::true_size
```

### Task 1.2.3: Inspect the `true_size` documentation

Using the `??data` prompt, you can inspect the contents of the data frame.

```{r}
??critstats::true_size
```

As noted before, this serves as the data's documentation and is the basis of a code book (or codebook). A codebook contains very specific details about a database, data set, and the variables each contains. We will explore codebooks more in the future.

------------------------------------------------------------------------

## Task 1.3: Explore the `true_size` data

### Task 1.3.1: Assign the `true_size` data frame to `df1`

Use the assignment operator to assign the `true_size` data frame to the object `df1`.

```{r}
df1 <- critstats::true_size
```

### Task 1.3.2: Inspect your data

Use the `str()` function to inspect your data frame.

`str()` displays the structure of R objects.

```{r}
str(df1)
```

You can also run similar commands separately:

#### Task 1.3.2a: `dim()`

Use the `dim()` function to check the dimensions of your data.

```{r}
# check the dimensions of your data
dim(df1)
```

Note that the dimensions are reported as a $n \times m$ matrix with $n$ rows and $m$ columns.

#### Task 1.3.2b: `view()`

Use the `View()` function to see all of your data in a separate window.

```{r, eval=F}
# view the data
View(df1)
```

#### Task 1.3.2c: `glimpse()`

Take a glimpse of your data using the `glimpse()` function.

```{r}
# get a glimpse of your data frame
glimpse(df1)
```

#### Task 1.3.2d: `head()`

View the first six observations in your data using the `head()` function.

```{r}
# view the "top" of your data
head(df1)
```

#### Task 1.3.2e: `tail()`

View the last six observations in your data using the `tail()` function.

```{r}
# view the "bottom" of your data
tail(df1)
```

#### Task 1.3.2f: Specify `n` in `head()` or `tail()`

You can change the number of observations viewed by being more explicit in your code.

```{r}
head(df1, n = 10) # view the top 10 observations
tail(df1, n = 3) # view the bottom 3 observations
```

#### Task 1.3.2g: `summary()`

Get a summary of all variables in the data set.

```{r}
# get a summary of your data frame
summary(df1)
```

------------------------------------------------------------------------

## Task 1.4: Use `dplyr` verbs on `true_size`

In this section, we will review the `dplyr` verbs that help us get our data into a format that works for our analysis. These verbs can be used in any order. We can also use the pipe operator `%>%` and use multiple verbs in a single code chunk.

### Task 1.4.1: Subset columns (variables) using `select()`

The `select()` command retains only those columns that are listed.

It uses the logic `select(data, variable1, variable2, ...)`.

```{r}
# keep only the Country and percent.africa columns
select(df1, Country, percent.africa) 

# keep only the Country and area.sq.mi columns
select(df1, Country, area.sq.mi)
```

We can also subset columns by deleting others

To do so, we use a minus sign ahead of the column names.

```{r}
# remove the area.sq.mi variable
select(df1, -area.sq.km)

# remove the listed variables in the data frame
select(df1, -area.sq.km, -area.sq.mi) 
```

### Task 1.4.2: Filter rows (cases) using `filter()`

`filter()` allows us to select rows based on specific criteria.

```{r}
# keep only those rows where the percent.africa value is grater than 30
filter(df1, percent.africa > 30)

# keep only those rows where the percent.africa value is less than 1
filter(df1, percent.africa < 1)

# keep only those rows where percent.africa is less than 10 and greater than 1
filter(df1, percent.africa < 10 & percent.africa > 1)

# keep only those rows where Country is equal to "China"
filter(df1, Country == "China")
```

Notice the use of a `==` equal sign when referencing a cell's value. This will become an important component of base logic and analysis when writing code.

### Task 1.4.3: Add/remove columns (variables) using `mutate()`

We use `mutate()` to create new variables from existing variables.

It is not clear what `area.sq.mi` and `area.sq.km` refer to in our data. Further inspection and a bit of internet searching will show us that these values are in the millions and that they represent estimates.

We can transform these as follows:

```{r}
# add a new column with a more accurate label for land area estimate (sq mi)
mutate(df1, est.square.miles = df1$area.sq.mi * 1000000) 
```

#### Task 1.4.3a: Add new variables using the pipe `%>%`

We can also use the `pipe` operator to mutate the variable.

```{r}
# we can create the same output when using the %>% (pipe)
df1 %>%
  mutate(est.square.miles = df1$area.sq.mi * 1000000) 

# add a new column with a more accurate label for land area estimate (sq km)
df1 %>% 
  mutate(est.square.km = df1$area.sq.km * 1000000)
```

#### Task 1.4.3b: Add new variables and remove old variables

It is easiest to put all of the verbs together in a single chunk of code.

```{r}
# remove the old column; use the pipe command to do both operations at once
df1 %>%
  mutate(est.square.miles = df1$area.sq.mi * 1000000) %>% 
  mutate(est.square.km = df1$area.sq.km * 1000000) %>% 
  select(-area.sq.mi, -area.sq.km) # remove the columns we do not want
```

These values seem to represent the data more clearly.

### Task 1.4.4: Rename a column using `rename()`

We can also use `rename()` to modify a column's label.

```{r}
df1 %>%
  mutate(est.square.miles = df1$area.sq.mi * 1000000) %>% 
  mutate(est.square.km = df1$area.sq.km * 1000000) %>% 
  select(-area.sq.mi, -area.sq.km)  %>% 
  rename(country = Country)  # make the 'C' in country lowercase
```

### Task 1.4.5: Use `relocate()` to reorder the columns

```{r}
df1 %>%
  mutate(est.square.miles = df1$area.sq.mi * 1000000) %>% 
  mutate(est.square.km = df1$area.sq.km * 1000000) %>% 
  select(-area.sq.mi, -area.sq.km)  %>% 
  rename(country = Country) %>% 
  relocate(country, percent.africa, est.square.miles) # reorder the columns
```

### Task 1.4.6: Overwrite your data frame

Now that we've restructured the data into a format that is more accurate, we can reassign our data frame using the pipe operator. Take note of how the code is built with new commands starting on a new line and ending with the `%>%` operator.

```{r}
true_size_modified <- df1 %>%
  mutate(est.square.miles = df1$area.sq.mi * 1000000) %>% 
  mutate(est.square.km = df1$area.sq.km * 1000000) %>% 
  select(-area.sq.mi, -area.sq.km)  %>% 
  rename(country = Country) %>% 
  relocate(country, percent.africa, est.square.miles) # reorder the columns
```

Now view your modified data frame.

```{r}
true_size_modified
```

### Task 1.4.7: Explore `summarise()`, `arrange()`, and other verbs

There are other verbs in the `dplyr` package.

For example, we will use the `summarise()` and `arrange()` commands in the next part of the case study.

You can learn more about other `dplyr` data transformations [here](https://github.com/rstudio/cheatsheets/blob/main/data-transformation.pdf).

------------------------------------------------------------------------

Now that you have a few tools to explore and modify data frames, we return to the `africa_data_all` data in the `critstats` package. We will use this data frame to work more with `dplyr` and explore univariate analyses.

------------------------------------------------------------------------

# Preparing Case Study and Lab Reports

Labs and case studies contain **Reports**. In this way, we have both *lab reports* and *case reports*.

Lab reports are for your own research papers. Case reports are for your exploratory work.

**Reports**, as the name may suggest, are meant to help you report out your own workflow.

Developing your own workflow is an important part of statistical analysis. Your workflow and reports should **not** be a `copy` and `paste` of the exact code outlined in a case study's examples. That said, most examples and the code used are specifically designed to help us move efficiently through the materials for this course.

Note: The use of internet resources like `Chat GPT` are discouraged when generating code. If an assignment is submitted after using any AI assisted software, there may be an issue with plagiarism. All code for our course is self-contained, and it should not require that you search for long hours to find a solution; all solutions are somewhere on our course site!

------------------------------------------------------------------------

# Part 1 Reports

## Report 1.1

What are some of the main concepts in [Vaughan (2018)](https://www.jstor.org/stable/j.ctv550dcj)? Could the data in the `true_size` data be used to respond to and advance our understanding of the concepts in Vaughan (2018)? If so, how might it be used to examine both the social context (period) and historical consequences (uses) of inequity in map making? If not, explain.

## Report 1.2

If the data in `true_size_modified` is accurate, what is the expected correlation between the percent.africa and est.square.miles variables? Specifically, why do we get the below scatter plot based on the data values?

```{r}
#| echo: false
#| output: true
plot(percent.africa ~ est.square.miles, true_size_modified)
```

## Report 1.3

Based on the original values in the `true_size` data, is there enough information to confirm if the claims about the size of Africa and the social politics of maps is true? Explain why or why not.

## Report 1.4

Write code to add a new variable to the `true_size_modified` data called `proportion`.

Use `mutate()` and arithmetic to generate the new variable.

Hint: If $Y$ = `proportion`, then $y_i = \dfrac{x_i}{sum(x)}$ for some variable $X$ in data set.

```{r}
#| echo: false
#| output: true
true_size_modified %>% 
  mutate(proportion = est.square.miles/sum(est.square.miles)) %>% 
  glimpse() %>% 
  head() %>% 
  tail()
```

Overwrite `true_size_modified` with a new data framed titled `true_size_updated`.

You should be able to call the data as follows:

```{r}
#| echo: false
#| output: false
true_size_modified %>% 
  mutate(proportion = est.square.miles/sum(est.square.miles)) %>% 
  glimpse() %>% 
  head() %>% 
  tail()
```

```{r}
#| echo: false
#| output: false
true_size_updated <- true_size_modified %>% 
  mutate(proportion = est.square.miles/sum(est.square.miles))
true_size_updated
```

```{r}
#| echo: true
#| output: true
true_size_updated
```

## Report 1.5

To confirm that you have generated the new variable and overwritten the data frame, create the plot below using the following code. Be sure to add your first name and last name in the quotes.

The code should be verbatim with the exception of your name.

```{r}
#| echo: true
#| output: true
plot(true_size_updated$proportion, true_size_updated$percent.africa)
title("first.name last.name") # Add your first name and last name
```

For example, my code would read:

```{r}
#| echo: true
#| output: true
plot(true_size_updated$proportion, true_size_updated$percent.africa)
title("Nathan Alexander") # Add your first name and last name
```

Notice the use of quotes when using `title()` under a plot.

If you experience issues making the plot, it is likely that you have made an error in the previous steps. Remember that R is case sensitive in all instances, and space sensitive in some instances.

Please be sure to go back and carefully check your code.

\Large{Save this plot as a `pdf` and submit it with case study files.

# Experiencing issues?

If you experience issues executing your code, check the notes below.

Remember that R is case sensitive in all instances, and space sensitive in some instances. Please be sure to go back and carefully check your code.

If you get the following error:

`lazy-load database ‘…rdb’ is corrupt`

Try the following method and re-install the package.

Restart your R session by running `.rs.restartR()` in your RStudio Console.

The package might have been installed in your computer (even though it does not work). Remove it using `'`?remove.packages()`'`.

Do not hesitate to contact me via email.
