{
  "hash": "dccd75814f4bc4e6bd757af00eb9d283",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"DATA 202 - Week 6\"\nsubtitle: \"Bivariate analysis\"\nauthor: \"Nathan Alexander, PhD\"\ninstitute: \"Center for Applied Data Science and Analytics\"\nformat: \n  html: default\n  revealjs:\n    output-file: week06-slides.html\n    height: 900\n    width: 1600\n    smaller: false\n    scrollable: true\n    slide-number: c/t #< collapsted/total\n    logo: \"img/howard-logo.jpg\"\n    footer: \"[Course Data GitHub](https://github.com/data-202)\"\n    toc: false\n    echo: true\n    incremental: false\n---\n\n\n\n\n\n\n## Part I: Context\n\n------------------------------------------------------------------------\n\n### Understanding the social in justice\n\nBuilding theories and empirical inquiries around various injustices requires a solid foundation.\n\n-   One method is to read recent articles in peer-reviewed journals.\n\n-   Another method is to explore the various ways one may view injustice.\n\n-   From a logical perspective, you may test the validity of certain claims.\n\nHow should we define social justice?\n\n-   Identify two to three definitions of social justice to share.\n\n    -   Locate a few open source articles or periodicals.\n\n-   What are the *similarities* between the different definitions?\n\n-   What are the *differences* between the different definitions?\n\n------------------------------------------------------------------------\n\n### Framing social justice\n\nThere are many different frameworks that have been developed to examine social justice.\n\nNorth (2006), as one example, discuss *three spheres of social justice* in the article \"More Than Words? Delving Into the Substantive Meaning(s) of Social Justice in Education.\" The abstract reads as follows:\n\n> \"At the dawning of the 21st century, the term \"social justice\" is appearing in numerous public texts and discourses throughout the field of education. However, and as Gewirtz argued in 1998, the conceptual underpinnings of this catchphrase frequently remain tacit or underexplored. This article elaborates Gewirtz's earlier \"mapping\" of social justice theories by examining the tensions that emerge when various conceptualizations of social justice collide and, in turn, their implications for the field of education. By presenting a model of the complex, fraught interactions among diverse claims about social justice, the author seeks to promote continued dialogue and reflexivity on the purposes and possibilities of education for social justice.\"\n\n![Three Spheres of Social Justice by [North (2006)](https://journals.sagepub.com/doi/10.3102/00346543076004507){target=\"_blank\"}](img/wk6-a-1.png){width=\"75%\"}\n\nIn her analysis, North deals specifically with three conceptions of social justice and their implications for educational research and practice. These frameworks, however, can be extended over to other fields of study. Consider how this framework might apply to your area of study.\n\n------------------------------------------------------------------------\n\nThere are different ways to consider these interrelated systems in your theory construction.\n\n#### Macro/Micro\n\n-   [Macro]{.underline}: Large-scale analyses, typically on systems or observations in the aggregate\n\n-   [Micro]{.underline}: Smaller-scale analyses, typically on individuals or localized contexts\n\n#### Sameness/Difference\n\n-   [Sameness]{.underline}: Considering homogeneous structures or characteristics; similarity\n\n-   [Difference]{.underline}: Considering heterogeneous structures or characteristics; non-uniformity\n\n#### Redistribution/Recognition\n\n-   [Redistribution]{.underline}: Primary considerations in economic or material conditions\n\n-   [Recognition]{.underline}: Primary considerations in cultural or social conditions\n\n------------------------------------------------------------------------\n\n## Part II: Content\n\nThis week's topics focus on bivariate analysis.\n\nThe goal of a bivariate analysis is to understand the relationship between two variables.\n\nThere are a few common ways to perform bivariate analysis:\n\n-   Estimating differences in proportions\n\n-   Scatter plots\n\n-   Correlation coefficients\n\n-   Simple linear regression\n\n------------------------------------------------------------------------\n\n### Simple linear regression\n\nA simple linear regression (sometimes referenced as a bivariate regression) is a linear equation describing the relationship between an **explanatory** variable and an **outcome** variable.\n\nThere is an assumption that the explanatory variable influences the outcome variable, and not the other way around.\n\nTake, for example, a variable $y_i$ which denotes the *income* of some individual in a sample, and we index this data using $i$ where $i \\in \\{1, 2, ..., n\\}$. We can let some other variable in our data $x_i$ represent the *years of education* for the same individual. A simple linear regression equation of these variables take the following form: $$y_i = b_0 + b_{1}x_{i} + e_i$$\n\nwhere $b_1$ is the sample estimate of the slope of the regression line with respect to the years of education and $b_0$ is the sample estimate for the vertical intercept of the regression line.\n\n------------------------------------------------------------------------\n\n### Correlation coefficients and scatterplots\n\nAs a reminder, correlation ranges from -1 to 1. It gives us an indication on two things:\n\n-   The direction of the relationship between the two variables\n\n-   The strength of the relationship between the two variables\n\nAny outliers can greatly impact the value of a correlation coefficient.\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(x,y)\n```\n\n::: {.cell-output-display}\n![](week06_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n### Estimating differences in proportions\n\nWhen generating cross tabulations, we can make sense of a few bivariate tests:\n\n-   Differences in proportions\n\n-   Standard errors of the difference in proportions\n\n-   Confidence intervals for the differences\n\n-   T-test for differences in proportions\n\n------------------------------------------------------------------------\n\n## Part III: Code\n\n------------------------------------------------------------------------\n\n### Write preamble\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ---\n# title: Exploring associations between income and political party in the US\n# subtitle: sample paper 2\n# author: Nathan Alexander\n# course: DATA 202 - fall 2023\n# ---\n\n# research inquiry: does income relate to political party support in the US?\n# data: 2020 sample data from the General Social Survey (GSS)\n# note(s): variables should be mutated and recoded into two levels\n```\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n### step 0: install packages and load libraries\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"tidyverse\", repos = \"http://cran.us.r-project.org\")\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(tidyr)\n```\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n### step 1: view `gss_cat` data in the package `forcats`\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngetwd() # check working directory\n?gss_cat # view data documentation\ngss_cat # call data frame\nglimpse(gss_cat) # glimpse data\nsummary(gss_cat) # view summary of data\n```\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n### step 2: clean and manage data\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngss_cat_clean <- gss_cat %>% \n  na.omit() %>% \n  select(year, rincome, partyid) %>% \n  rename(income = rincome) %>% \n  rename(party = partyid)\n\ngss_cat_clean # view cleaned data\n```\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n### step 3: subset data: year == 2000\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- gss_cat_clean %>% \n  filter(year==2000)\n\nhead(df) # view top of data\ntail(df) # view bottom of data\nsummary(df) # check data\n```\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n### step 4: inspect and transform income variable into two levels\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## create a frequency table of each level in the income variable\ndf %>% count(party)\n\n## drop 'No answer', 'Don't know', 'Refused', and 'Not applicable' levels\ndf <- df %>%  \n  filter(income != \"No answer\",\n         income != \"Don't know\",\n         income != \"Refused\",\n         income != \"Not applicable\") %>% \n  droplevels() # use droplevels() to remove levels from variable for factors\n\n## use levels() function to view levels for income variable\nlevels(df$income)\n\n## create two levels: below $20,000 and above $20,000\ndf <- df %>% \n  mutate(income = fct_recode(income, \n                             \"More than 20000\" = \"$25000 or more\",\n                             \"More than 20000\" = \"$20000 - 24999\",\n                             \"Less than 20000\" = \"$15000 - 19999\",\n                             \"Less than 20000\" = \"$10000 - 14999\",\n                             \"Less than 20000\" = \"$8000 to 9999\",\n                             \"Less than 20000\" = \"$7000 to 7999\",\n                             \"Less than 20000\" = \"$6000 to 6999\",\n                             \"Less than 20000\" = \"$5000 to 5999\",\n                             \"Less than 20000\" = \"$4000 to 4999\",\n                             \"Less than 20000\" = \"$3000 to 3999\",\n                             \"Less than 20000\" = \"$1000 to 2999\",\n                             \"Less than 20000\" = \"Lt $1000\"))\n\n## view a summary of your transformed data frame\nsummary(df)\n```\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n### step 5: inspect and transform party variable into two levels\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## create a frequency table of each level in the party variable\ndf %>% count(party)\n\n## drop 'No answer', 'Independent' and 'Other Party' levels\ndf <- df %>%  \n  filter(party != \"No answer\",\n         party != \"Independent\",\n         party != \"Other party\") %>% \n  droplevels() # use droplevels() to remove levels from variable for factors\n\n## create two levels: 'Republican' and 'Democrat'\ndf <- df %>% \n  mutate(party = fct_recode(party,\n                            \"Republican\" = \"Strong republican\",\n                            \"Republican\" = \"Not str republican\",\n                            \"Republican\" = \"Ind,near rep\",\n                            \"Democrat\" = \"Ind,near dem\",\n                            \"Democrat\" = \"Not str democrat\",\n                            \"Democrat\" = \"Strong democrat\"))\n\n## remove year from data frame\ndf <- df %>% \n  select(-year)\n\n## view a summary of the data to check for any errors\nsummary(df)\n```\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n### step 6: visualize data\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## create a frequency table and bar graph of income \ntable.income = table(df$income)\ntable.income\nbarplot(table.income,\n        main = \"Bar graph of Income\",\n        xlab = \"Respondent Income\",\n        ylab = \"Frequency\")\n```\n\n```{.r .cell-code}\n## the below code produces the same output as above with specifications\nbarplot(table(df$income),\n        main = \"Bar graph of Income\",\n        col = \"lightgreen\",\n        xlab = \"Respondent Income\",\n        ylab = \"Frequency\",\n        ylim = c(0,650)) # this y-axis range: (0, 650) works best for my plot\n```\n\n```{.r .cell-code}\n## create a frequency table and bar graph of party \ntable.party = table(df$party)\ntable.party\nbarplot(table.party,\n        main = \"Bar graph of Party\",\n        xlab = \"Respondent Party\",\n        ylab = \"Frequency\")\n```\n\n```{.r .cell-code}\n## the below code produces the same output as above with specifications\nbarplot(table(df$party),\n        main = \"Bar graph of Party\",\n        col = c(\"red\",\"blue\"),\n        xlab = \"Respondent Party\",\n        ylab = \"Frequency\",\n        ylim = c(0,600)) # this y-axis range: (0, 550) works best for my plot\n```\n\n```{.r .cell-code}\n## create a stacked bar plot of the proportions\n#### question: which of the two plots do you prefer, why?\nplot(df$income, df$party)\n```\n\n```{.r .cell-code}\nplot(df$party, df$income)\n```\n\n```{.r .cell-code}\n## the below code produces similar outputs as above with specifications\nplot(df$party, df$income,\n     main = \"Mosaic Plot of Political Party and Income\",\n     col = c(\"lightyellow\",\"lightgreen\"),\n     xlab = \"Political Party\",\n     ylab = \"Income\")\n```\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n### step 7: create a basic cross tab for manual calculations\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## gather sample size\nn = count(df)\nn\n\n## view a basic cross tabulation\ntable(df$income, df$party)\n```\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n### step 8: bivariate analysis\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## load required libraries (and packages, where needed)\ninstall.packages(\"descr\", repos = \"http://cran.us.r-project.org\")\nlibrary(descr)\n\ninstall.packages(\"Hmisc\", repos = \"http://cran.us.r-project.org\")\nlibrary(Hmisc)\n\n## create a cross tab (list dependent variable in your hypothesis first)\ncrosstab(df$party, df$income)\n\n## add column percentages to the cross tab\ncrosstab(df$party, df$income,\n         prop.c=T) # add column percentages\n```\n\n```{.r .cell-code}\n## add row percentages to the cross tab\ncrosstab(df$party, df$income,\n         prop.r=T) # add row percentages\n\n## get expected frequencies and cell chi-square contributions\ncrosstab(df$party, df$income,\n         expected = T, # get expected values\n         prop.chisq=T) # get chi-square contribution\n\n## get critical value of chi-square, p=.05, df=1\n#### recall: df = (r-1)(c-1)\nqchisq(.05, 1, lower.tail=F)\n\n## get chi-square statistic\nchisq.test(df$party, df$income)\n```\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n### step 9: describe some initial limitations of analysis\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### limitation 1: sampling error\n# data come from a sample and there are likely differences in other samples\n\n### limitation 2: category reductions\n# creating two levels for the variables greatly impacted the diversity of responses\n\n### limitation 3: cases dropped\n# sample was further impacted by the number of values dropped in the analysis\n\n### limitation 4: chi-square test\n# the chi-square test does not tell us about the strength or direction of association\n```\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n### **Next up**: Week 7\n",
    "supporting": [
      "week06_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}