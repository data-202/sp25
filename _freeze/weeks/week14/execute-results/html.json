{
  "hash": "0cdbb79ba90196c1b84ef8462489fbb3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"DATA 202 - Week 14\"\nsubtitle: \"Multivariate regression\"\nauthor: \"Nathan Alexander, PhD\"\ninstitute: \"Center for Applied Data Science and Analytics\"\nformat: \n  html: default\n  revealjs:\n    output-file: week14-slides.html\n    height: 900\n    width: 1600\n    smaller: false\n    scrollable: true\n    slide-number: c/t #< collapsed/total\n    logo: \"img/howard-logo.jpg\"\n    footer: \"[Course Data GitHub](https://github.com/data-202)\"\n    toc: false\n    echo: true\n    incremental: false\n    self-contained: true\n---\n\n\n\n\n\n\n## Part I: Context\n\nNow that we have many foundational elements identified and practiced - such as generating code to explore data, cleaning data for analysis, and some elements of theory construction - we can begin focusing on some of the important technical components of model building and analysis: interpretation.\n\n-   Interpretation relies very heavily on both your research question and the subsequent empirical study.\n\n-   While your research question may be based on a host of factors, your empirical study relies on a combination of:\n\n    -   Theoretical **frameworks**\n\n    -   Analytic **method**\n\n    -   **Interpretations**\n\n------------------------------------------------------------------------\n\n![A suggestive and indicative mode of the triangulation method from [Tzagkarakis & Kritas (2023)](https://link.springer.com/article/10.1007/s11135-022-01384-y).](img/wk14-a-1.png)\n\n------------------------------------------------------------------------\n\n### Research questions\n\nThe below research questions highlight the intersection of social justice issues in multiple variable quantitative analysis. Keep in mind that these questions can be further refined and tailored to specific contexts or issues of interest within the realm of social justice.\n\n1.  How does income inequality and geographical location affect access to quality education?\n\n2.  What disparities in the criminal justice system by race and gender?\n\n3.  How does gender discrimination and age impact career advancement in the workplace?\n\n4.  What are the effects of housing policies and income on residential segregation and access to affordable housing?\n\n5.  How does healthcare accessibility and affordability vary across different socioeconomic groups?\n\n------------------------------------------------------------------------\n\n### Sample analysis\n\nLet us continue with a sample analysis.\n\nWe will assume that state data collected for a sample of 100 randomly selected cities requesting funding after the approval of a new bill on affordable housing. The data set includes three key variables.\n\nResearch question\n\n:   What is the relationship between state funding for affordable housing initiatives and the availability of new affordable housing units?\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\nDetails about each variable are provided below:\n\n-   `city` is a marker (which matches the data index) used to indicate a randomly selected city.\n\n-   `funding` is the total amount of funding provided to families (in thousands of dollars) in a given 3-week period\n\n-   `housing_availability` is the average of city housing units allocated over the same `funding` period\n\n-   `advocacy` is the average number of calls to the state representatives' hotline four months prior\n\nThe advocacy variable was generated as a result of a similar study conducted in a neighboring state, which noticed that there was a potential lag-relationship between `advocacy` and `funding` allocations approved at the state-level.\n\n------------------------------------------------------------------------\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  city funding housing_availability advocacy\n1    1  251.32                34.60    21.15\n2    2  422.71                50.32    35.27\n3    3  418.33                45.47    28.54\n4    4  423.08                46.43    27.23\n5    5  503.13                55.97    36.67\n6    6  428.78                60.77    27.49\n```\n\n\n:::\n\n```{.r .cell-code}\ntail(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    city funding housing_availability advocacy\n95    95  248.48                55.39    18.27\n96    96  385.40                58.23    33.48\n97    97  314.17                67.69    26.19\n98    98  222.00                52.38    22.95\n99    99  317.35                57.37    18.10\n100  100  463.09                59.65    27.02\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      city           funding      housing_availability    advocacy    \n Min.   :  1.00   Min.   :216.2   Min.   :34.60        Min.   :16.19  \n 1st Qu.: 25.75   1st Qu.:280.4   1st Qu.:48.54        1st Qu.:22.52  \n Median : 50.50   Median :343.4   Median :54.97        Median :27.04  \n Mean   : 50.50   Mean   :360.4   Mean   :54.54        Mean   :26.63  \n 3rd Qu.: 75.25   3rd Qu.:437.7   3rd Qu.:59.55        3rd Qu.:30.30  \n Max.   :100.00   Max.   :547.4   Max.   :77.86        Max.   :37.34  \n```\n\n\n:::\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n### Exploration\n\nWe can use some base-R commands to get a quick summary of each variable.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get plots of variables\nhist(funding)\n```\n\n::: {.cell-output-display}\n![](week14_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(housing_availability)\n```\n\n::: {.cell-output-display}\n![](week14_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n### Exploration\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get summary statistics for variables\nsummary(funding)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  216.2   280.4   343.4   360.4   437.7   547.4 \n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(housing_availability)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  34.60   48.54   54.97   54.54   59.55   77.86 \n```\n\n\n:::\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](week14_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](week14_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\nWe can also produce quick plots to examine the relationship between each variable.\n\nHere, we include code to get the correlation coefficient.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# perform correlation analysis\nplot(funding, housing_availability)\n```\n\n::: {.cell-output-display}\n![](week14_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncor(funding, housing_availability)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.266359\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(advocacy, funding)\n```\n\n::: {.cell-output-display}\n![](week14_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n\n```{.r .cell-code}\ncor(advocacy, funding)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4757307\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(advocacy, housing_availability)\n```\n\n::: {.cell-output-display}\n![](week14_files/figure-html/unnamed-chunk-8-3.png){width=672}\n:::\n\n```{.r .cell-code}\ncor(advocacy, housing_availability)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1444811\n```\n\n\n:::\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n### Interpretation\n\nFirst, researchers decided to run a linear regression model on `housing_availability` and `funding`.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# perform linear regression analysis\nmodel1 <- lm(housing_availability ~ funding)\n\n# summary of the regression model\nsummary(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = housing_availability ~ funding)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.1793  -5.9060  -0.6551   5.0543  22.4049 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 45.49080    3.41826  13.308  < 2e-16 ***\nfunding      0.02511    0.00918   2.736  0.00739 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.579 on 98 degrees of freedom\nMultiple R-squared:  0.07095,\tAdjusted R-squared:  0.06147 \nF-statistic: 7.484 on 1 and 98 DF,  p-value: 0.007391\n```\n\n\n:::\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n##### Plot the data and regression line\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data, aes(x = funding, y = housing_availability)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"City Funding\", y = \"Housing Availability\", title = \"Relationship between City Funding and Housing Availability\")\n```\n\n::: {.cell-output-display}\n![](week14_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\nOne researcher, however, suggested that a more **robust regression analysis** should be used with OLS techniques. Robust regression analysis, as you may recall, helps us reduce outlier effects.\n\nNote: we need to load the `MASS` package and library to run the following code.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nols <- lm(housing_availability ~ funding)\nsummary(ols)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = housing_availability ~ funding)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-18.1793  -5.9060  -0.6551   5.0543  22.4049 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 45.49080    3.41826  13.308  < 2e-16 ***\nfunding      0.02511    0.00918   2.736  0.00739 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.579 on 98 degrees of freedom\nMultiple R-squared:  0.07095,\tAdjusted R-squared:  0.06147 \nF-statistic: 7.484 on 1 and 98 DF,  p-value: 0.007391\n```\n\n\n:::\n\n```{.r .cell-code}\nopar <- par(mfrow = c(2, 2), oma = c(0, 0, 1.1, 0))\nplot(ols, las = 1)\n```\n\n::: {.cell-output-display}\n![](week14_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n```{.r .cell-code}\npar(opar) # we use the par() function to restore graphical parameters to their original values\n```\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\nFrom this analysis, we see that a few observations are possibly problematic to our model.\n\nWe can explore some of these observations in more detail.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata[c(12, 50, 73), 1:4]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   city funding housing_availability advocacy\n12   12  396.66                77.86    30.15\n50   50  470.96                75.79    22.38\n73   73  217.93                68.29    27.94\n```\n\n\n:::\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\nThe three cities noted (and there may be others) have large residuals.\n\nWe can examine these in more detail.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndistance <- cooks.distance(ols) # we get a measure of the Cook's distance values.\nres <- stdres(ols)\na <- cbind(data, distance, res)\na[distance > 4/100, ]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   city funding housing_availability advocacy   distance       res\n1     1  251.32                34.60    21.15 0.04984715 -2.029432\n7     7  216.20                64.53    17.56 0.04561739  1.614402\n12   12  396.66                77.86    30.15 0.04014294  2.626744\n16   16  495.17                73.25    25.20 0.05225347  1.813880\n50   50  470.96                75.79    22.38 0.05837888  2.179622\n73   73  217.93                68.29    27.94 0.07252929  2.053558\n75   75  243.32                67.02    20.18 0.04371737  1.820393\n78   78  236.61                36.76    16.89 0.04260811 -1.734093\n```\n\n\n:::\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\nThe decisions were made based on the following notes:\n\n-   Cook's distance `cooks.distance()` provides a measure of the influence of a data point when performing regression.\n\n-   `stdres` standardized the residuals from our model\n\n-   `cbind()` attaches the two measures to our data frame\n\nWe can use a cutoff point $4/n$ where $n$ is the sample size recommend by others to select the values to display.\n\n------------------------------------------------------------------------\n\nWe then get the absolute value of the residuals (remember that the sign does not matter in distance), and we print the observations with the highest residuals (here we focus on the top 10 values).\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nabsres <- abs(res)\ndata1 <- cbind(data, distance, res, absres)\nassorted <- data1[order(-absres), ]\nassorted[1:10,]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   city funding housing_availability advocacy   distance       res   absres\n12   12  396.66                77.86    30.15 0.04014294  2.626744 2.626744\n50   50  470.96                75.79    22.38 0.05837888  2.179622 2.179622\n88   88  317.76                35.29    20.73 0.02780093 -2.131960 2.131960\n25   25  286.74                70.57    22.02 0.03637332  2.100555 2.100555\n73   73  217.93                68.29    27.94 0.07252929  2.053558 2.053558\n1     1  251.32                34.60    21.15 0.04984715 -2.029432 2.029432\n85   85  279.11                36.86    19.93 0.03027410 -1.839822 1.839822\n75   75  243.32                67.02    20.18 0.04371737  1.820393 1.820393\n16   16  495.17                73.25    25.20 0.05225347  1.813880 1.813880\n78   78  236.61                36.76    16.89 0.04260811 -1.734093 1.734093\n```\n\n\n:::\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\nWe now run our robust regression analysis.\n\nWe do this by using the `rlm()` function in the `MASS` package.\n\nThere are several weights that can be used for the iterated re-weighted least squares technique (IRLS)[^1].\n\n[^1]: More information about the source of this code and the robust regression analysis can be found [here](https://stats.oarc.ucla.edu/r/dae/robust-regression/).\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrrmodel <- rlm(housing_availability ~ funding, data = data)\nsummary(rrmodel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall: rlm(formula = housing_availability ~ funding, data = data)\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.9198  -5.4416  -0.3424   5.2609  22.8048 \n\nCoefficients:\n            Value   Std. Error t value\n(Intercept) 45.7779  3.5798    12.7880\nfunding      0.0234  0.0096     2.4328\n\nResidual standard error: 8.213 on 98 degrees of freedom\n```\n\n\n:::\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\nThe default weight is the Huber weight.\n\nHuber weights are a type of weight function used to downweight or mitigate the influence of outliers on the estimation procedure.\n\nIn traditional least squares regression, all data points are given equal weight, and the estimation procedure is sensitive to the presence of outliers. The use of weights in our robust regression model aims to provide more robust estimates by assigning different weights to the observations, giving less influence to outliers.\n\n------------------------------------------------------------------------\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhweights <- data.frame(city = data$city, resid = rrmodel$resid, weight = rrmodel$w)\nhweights2 <- hweights[order(rrmodel$w),]\nhweights2[1:15,]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   city     resid    weight\n12   12  22.80484 0.4843946\n50   50  18.99708 0.5814916\n25   25  18.08570 0.6107904\n88   88 -17.91981 0.6164041\n73   73  17.41506 0.6343102\n1     1 -17.05588 0.6476276\n16   16  15.89084 0.6951638\n75   75  15.55123 0.7103366\n85   85 -15.44584 0.7151312\n43   43  14.97271 0.7377868\n97   97  14.56416 0.7584838\n78   78 -14.55183 0.7590662\n9     9  14.36036 0.7692537\n7     7  13.69553 0.8065877\n33   33 -12.74093 0.8669457\n```\n\n\n:::\n:::\n\n\n\n\n\n\nHuber weights assign larger weights to observations that are close to the regression line and smaller weights to observations that deviate significantly from the line. The weight assigned to each observation depends on its residuals (the difference between the observed values and the predicted values).\n\n------------------------------------------------------------------------\n\n#### Causality\n\nDespite our work on the initial model, the issue of causality needs to be discussed.\n\nThere are a few considerations that need to be taken into account:\n\n-   **Confounding variables**: There may be other factors that influence the model apart from city funding. For example, economic conditions, housing availability, and social policies can also play significant roles. Failing to account for these confounding variables may lead to erroneous conclusions about the causal relationship.\n\n-   **Reverse causality**: The relationships can be bidirectional. Higher housing availability rates may lead to increased city funding directed at addressing the issue. Thus, it's possible that the relationship is driven by reverse causality, where higher levels of housing availability cause increased funding rather than the other way around.\n\n-   **Omitted variable bias**: There may be unobserved or unmeasured factors that affect both city funding and housing availability. Failing to include these variables in the analysis can lead to omitted variable bias, potentially distorting the estimated relationships.\n\n-   **Ecological fallacy**: Analyzing aggregated data across the state- and city- levels may not capture the correct level of nuances within the relationship. Aggregating data can lead to an ecological fallacy, where conclusions made at the aggregate level may not hold true at different levels.\n\n------------------------------------------------------------------------\n\n#### Multicollinearity\n\nMulticollinearity refers to a high correlation or linear relationship between two or more predictor variables in a regression model. In the case of three variables, multicollinearity occurs when there is a strong linear relationship between any pair of the three variables, making it difficult to separate their individual effects on the response variable. This can cause instability in the regression model, inflated standard errors, and difficulties in interpreting the coefficients.\n\n------------------------------------------------------------------------\n\nAssume we updated our theoretical statement and research question and add the `advocacy` variable to our model.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# perform linear regression analysis\nmodel2 <- lm(housing_availability ~ funding + advocacy)\n\n# summary of the regression model\nsummary(model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = housing_availability ~ funding + advocacy)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.9890  -6.1250  -0.6158   4.9763  22.3024 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 44.80516    4.77827   9.377 2.97e-15 ***\nfunding      0.02408    0.01049   2.296   0.0238 *  \nadvocacy     0.03969    0.19229   0.206   0.8369    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.621 on 97 degrees of freedom\nMultiple R-squared:  0.07136,\tAdjusted R-squared:  0.05221 \nF-statistic: 3.727 on 2 and 97 DF,  p-value: 0.02759\n```\n\n\n:::\n:::\n\n\n\n\n\n\n#### Interaction effects\n\nNext, we add an interaction term to our model.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get a summary of the advocacy data\nsummary(advocacy)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  16.19   22.52   27.04   26.63   30.30   37.34 \n```\n\n\n:::\n\n```{.r .cell-code}\n# examine the relationship between funding and advocacy\ncor(advocacy, funding)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4757307\n```\n\n\n:::\n\n```{.r .cell-code}\n# perform linear regression analysis\nmodel3 <- lm(housing_availability ~ funding + advocacy + funding*advocacy)\n\n# summary of the regression model\nsummary(model3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = housing_availability ~ funding + advocacy + funding * \n    advocacy)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.9963  -6.2218  -0.5457   4.8889  22.3465 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)   \n(Intercept)      49.0944885 17.5511591   2.797  0.00623 **\nfunding           0.0117777  0.0495659   0.238  0.81268   \nadvocacy         -0.1236422  0.6712607  -0.184  0.85425   \nfunding:advocacy  0.0004576  0.0018009   0.254  0.79997   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.663 on 96 degrees of freedom\nMultiple R-squared:  0.07198,\tAdjusted R-squared:  0.04298 \nF-statistic: 2.482 on 3 and 96 DF,  p-value: 0.06555\n```\n\n\n:::\n:::\n\n\n\n\n\n\nPlease note that we may need to run additional tests or more robust models to inform interpretation.\n\n------------------------------------------------------------------------\n\n#### Statistical vs. practical significance\n\nWhen analyzing the relationship between state funding and housing availability, it is important to consider both statistical significance and practical significance.\n\n*Statistical significance* refers to the likelihood that the observed relationship or difference between variables is not due to chance. It is determined through statistical tests, such as hypothesis testing or p-values. In this context, statistical significance would indicate whether there is evidence to suggest that state funding has a statistically significant effect on housing availability. A statistically significant result suggests that the relationship between the variables is unlikely to have occurred by random chance.\n\n*Practical significance* focuses on the magnitude or practical importance of the observed relationship. It asks whether the observed effect size is meaningful or substantial in real-world terms. In the case of state funding and housing availability, practical significance would involve evaluating whether the observed impact of state funding on housing availability is large enough to have a meaningful or substantial effect on the availability of housing units.\n\nNote, however, that while statistical significance provides evidence of a relationship, it does not necessarily imply practical importance. A statistically significant relationship may exist but have a negligible or trivial effect in practice. Conversely, a relationship may have practical significance, even if it does not reach statistical significance due to limited sample size or other factors.\n\n------------------------------------------------------------------------\n\n### Replication studies\n\nExploring varied statistical outputs and their significance in a social justice context requires care, both in terms of the underlying theories that relate to the variables themselves and their use across different context. An additional factor that we have discussed relates to the role of the theoretical constructions and their applicability to issues of social injustice.\n\nMore often than not, caution should take the lead when developing new models. In these instances, some variation on what is known as a replication study can become a valuable tool. A *replication study* is a type of study that aims to reproduce or replicate the findings of a previous study. In the context of our course, the replication frameworks can be applied to examine the relationships between variables across contexts and different populations.\n\nThere are different types of replication studies.\n\n-   **Direct replication**: In this replication study type, researchers attempt to reproduce the original study as closely as possible, meaning they follow the same research design, methodologies, and data analysis procedures.\n\n-   **Partial replication**: In this replication study type, researchers attempt to replicate only a portion of the original study. Often, researchers doing a partial replication study focus on a specific aspect, variable, or component of the study.\n\n-   **Conceptual replication**: In this replication study type, researchers conduct a replication analysis that focuses on the same research question(s) but through the use of different methods, measures, or population groups.\n\nWhile replication studies are often used to help ensure the credibility and seeming generalizations found in statistical research findings, they can also serve as a part of a broader process to examine the role of context in statistical models. Importantly, failure to replicate the findings of a study do not mean that the original study findings were incorrect or flawed. Together, these types of explorations can contribute to scientific knowledge and provide evidence to help us understand the role of theory and the practice of social justice.\n\n------------------------------------------------------------------------\n\n### Beyond regression\n\nResearchers have access to a wide range of advanced statistical techniques and methodologies that provide deeper insights into complex relationships and patterns within data. These approaches go beyond the linear relationships examined in regression analysis and allow researchers to explore non-linear, interactive, and dynamic effects among variables. By utilizing these advanced techniques, researchers can uncover hidden patterns, make more accurate predictions, account for complex interactions, and gain a more comprehensive understanding of the phenomena under investigation.\n\nSome of these methods often provide greater flexibility in handling missing data, dealing with outliers, and accommodating various types of data structures. Overall, the utilization of these advanced statistical techniques expands the availability of tools to consider ways to delve deeper into the complexities of their data and extract meaningful insights.\n\n## Part II: Content\n\nMultiple Variable Analysis and Multivariate Analysis are two terms often used in statistics and research methodology to describe different approaches to analyzing data involving multiple variables. While they share similarities, there are distinct differences between these two concepts.\n\n------------------------------------------------------------------------\n\n### Multivariable vs. Multivariate\n\n*Multiple variable analysis* investigates the influence of individual independent variables on a single dependent variable, while *multivariate analysis* explores the relationships and patterns among multiple variables simultaneously.\n\nMultiple Variable Analysis is often used when studying the effects of specific factors, while multivariate analysis is employed to uncover broader patterns and structures within a dataset. Both approaches are valuable in data analysis, and the choice between them depends on the research objectives and the nature of the data being analyzed.\n\n------------------------------------------------------------------------\n\n::: {.callout-caution icon=\"false\"}\n#### **Definitions**: Multiple variable analysis vs. Multivariate analysis\n\n**Multiple Variable Analysis**: Multiple Variable Analysis refers to the process of examining the relationships between several independent variables and a single dependent variable. It aims to understand how each independent variable influences or predicts the dependent variable individually, while controlling for other variables. In this analysis, each independent variable is analyzed separately, often using techniques such as regression analysis or analysis of variance (ANOVA).\n\n**Multivariate Analysis**: Multivariate Analysis involves the simultaneous analysis of multiple dependent and independent variables. It aims to explore the relationships and patterns among multiple variables, considering them as a whole. This analysis technique allows for the examination of complex interactions and associations between variables, providing a more comprehensive understanding of the data.\n:::\n\n------------------------------------------------------------------------\n\n#### Key characteristics of multiple variable analysis\n\n1.  **Focus**: Examining the impact of individual independent variables on a single dependent variable.\n\n2.  **Analytic approach**: Each independent variable is analyzed separately, allowing for isolation of their effects.\n\n3.  **Purpose**: To identify the individual contributions and significance of multiple variables in explaining the variation in the dependent variable.\n\n4.  **Statistical techniques**: Common techniques include simple linear regression, multiple linear regression, and ANOVA.\n\n------------------------------------------------------------------------\n\n#### Key characteristics of multivariate analysis\n\n1.  **Focus**: Examining the relationships and interactions among multiple variables simultaneously.\n\n2.  **Analytic approach**: Considering all variables together, accounting for their joint effects and potential interdependence.\n\n3.  **Purpose**: To explore patterns, associations, and structures within the data, identifying underlying factors or dimensions.\n\n4.  **Statistical techniques**: Common techniques include factor analysis, principal component analysis, cluster analysis, and structural equation modeling.\n\n------------------------------------------------------------------------\n\n### Examples of multivariate analysis techniques\n\n-   *Principal component analysis (PCA)*: PCA is used to reduce the dimensionality of data by transforming it into a new set of uncorrelated variables called principal components. R functions for PCA include `prcomp()` and `princomp()`.\n\n-   *Factor analysis*: Factor Analysis aims to identify latent factors that explain the correlations among observed variables. R offers functions like `factanal()` and `psych::fa()` for conducting factor analysis.\n\n-   *Canonical correlation analysis (CCA)*: CCA examines the relationships between two sets of variables and identifies the linear combinations of each set that have maximum correlation with each other. The `CCA()` function in the stats package can be used for this analysis.\n\n-   *Cluster analysis*: Cluster Analysis groups similar observations into clusters based on the similarity of their characteristics. R provides various clustering techniques, such as k-means clustering (`kmeans()`), hierarchical clustering (`hclust()`), and model-based clustering (`Mclust()`).\n\n-   *Discriminant analysis*: Discriminant Analysis aims to find a linear combination of variables that maximally separate predefined groups or classes. R offers functions like `lda()` and `qda()` for performing Linear Discriminant Analysis (LDA) and Quadratic Discriminant Analysis (QDA), respectively.\n\n-   *Multivariate regression*: Multivariate Regression extends simple linear regression to multiple response variables. The `lm()` function in R can be used for multivariate regression analysis.\n\n-   *Multivariate analysis of variance (MANOVA)*: MANOVA extends the analysis of variance (ANOVA) to multiple response variables simultaneously. The `manova()` function in R can be used for MANOVA.\n\n-   *Multidimensional scaling (MDS)*: MDS visualizes the similarity or dissimilarity between objects in a lower-dimensional space. R provides functions like `cmdscale()` and `isoMDS()` for performing MDS.\n\n-   *Structural Equation Modeling (SEM)*: SEM is a comprehensive framework for testing complex relationships among variables. R packages like lavaan and sem offer functionalities for conducting SEM.\n\n-   *Correspondence Analysis*: Correspondence Analysis explores the associations between categorical variables and visualizes them in a low-dimensional space. The `ca()` function in the ca package is commonly used for correspondence analysis.\n\nWe will consider a few of these models in our final weeks for the course.\n\n------------------------------------------------------------------------\n\n## Part III: Code\n\nThis week, we use some standard data included in R to further discuss model interpretation.\n\nWhile these data sets do not directly connect to the content of our course, they provide some useful examples to return to as they are discussed on many websites that use `R` and that can be found in online forums.\n\nEach example illustrates different scenarios for interpreting linear models using the summary output. Remember to consider coefficients, standard errors, t-values, and p-values to assess the significance and direction of relationships between predictors and the response variable. Additionally, theory construction and relevant knowledge and context are crucial for a comprehensive interpretation of the results.\n\n------------------------------------------------------------------------\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\nThis data is from the 1974 Motor Trend US magazine. The data set comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973--74 models). You could run similar models using data in the `critstats` package.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(mtcars)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"mpg\"  \"cyl\"  \"disp\" \"hp\"   \"drat\" \"wt\"   \"qsec\" \"vs\"   \"am\"   \"gear\"\n[11] \"carb\"\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(mtcars)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec             vs        \n Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n       am              gear            carb      \n Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n Median :0.0000   Median :4.000   Median :2.000  \n Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :1.0000   Max.   :5.000   Max.   :8.000  \n```\n\n\n:::\n:::\n\n\n\n\n\n\n#### Example 1: Simple Linear Regression\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit a simple linear regression model\nmodel <- lm(mpg ~ hp, data = mtcars)\n\n# Print the model summary\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mpg ~ hp, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.7121 -2.1122 -0.8854  1.5819  8.2360 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 30.09886    1.63392  18.421  < 2e-16 ***\nhp          -0.06823    0.01012  -6.742 1.79e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.863 on 30 degrees of freedom\nMultiple R-squared:  0.6024,\tAdjusted R-squared:  0.5892 \nF-statistic: 45.46 on 1 and 30 DF,  p-value: 1.788e-07\n```\n\n\n:::\n:::\n\n\n\n\n\n\nThe summary output provides information about the coefficients, standard errors, t-values, and p-values. In this case, the intercept represents the estimated baseline miles per gallon (mpg) when horsepower is zero. The coefficient for horsepower indicates the estimated change in mpg for each unit increase in horsepower.\n\n------------------------------------------------------------------------\n\n#### Example 2: Multiple Linear Regression\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit a multiple linear regression model\nmodel <- lm(mpg ~ hp + wt, data = mtcars)\n\n# Print the model summary\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mpg ~ hp + wt, data = mtcars)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.941 -1.600 -0.182  1.050  5.854 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 37.22727    1.59879  23.285  < 2e-16 ***\nhp          -0.03177    0.00903  -3.519  0.00145 ** \nwt          -3.87783    0.63273  -6.129 1.12e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.593 on 29 degrees of freedom\nMultiple R-squared:  0.8268,\tAdjusted R-squared:  0.8148 \nF-statistic: 69.21 on 2 and 29 DF,  p-value: 9.109e-12\n```\n\n\n:::\n:::\n\n\n\n\n\n\nThe summary output provides interpretation for each coefficient. For example, the coefficient for horsepower represents the estimated change in mpg for each unit increase in horsepower, holding weight constant. Similarly, the coefficient for weight represents the estimated change in mpg for each unit increase in weight, holding horsepower constant.\n\n------------------------------------------------------------------------\n\n#### Example 3: Categorical Predictor\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit a linear regression model with a categorical predictor\nmodel <- lm(mpg ~ factor(cyl), data = mtcars)\n\n# Print the model summary\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mpg ~ factor(cyl), data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.2636 -1.8357  0.0286  1.3893  7.2364 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   26.6636     0.9718  27.437  < 2e-16 ***\nfactor(cyl)6  -6.9208     1.5583  -4.441 0.000119 ***\nfactor(cyl)8 -11.5636     1.2986  -8.905 8.57e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.223 on 29 degrees of freedom\nMultiple R-squared:  0.7325,\tAdjusted R-squared:  0.714 \nF-statistic:  39.7 on 2 and 29 DF,  p-value: 4.979e-09\n```\n\n\n:::\n:::\n\n\n\n\n\n\nWhen a categorical predictor, such as \"cyl\" (number of cylinders), is included in the model, R automatically treats it as a set of dummy variables. The summary output provides the coefficients for each category level (e.g., 4 cylinders, 6 cylinders, 8 cylinders). These coefficients represent the estimated difference in the response variable (mpg) compared to the reference category (usually the intercept).\n\n------------------------------------------------------------------------\n\n#### Example 4: Interaction Effect\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit a linear regression model with an interaction term\nmodel <- lm(mpg ~ hp * wt, data = mtcars)\n\n# Print the model summary\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mpg ~ hp * wt, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0632 -1.6491 -0.7362  1.4211  4.5513 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 49.80842    3.60516  13.816 5.01e-14 ***\nhp          -0.12010    0.02470  -4.863 4.04e-05 ***\nwt          -8.21662    1.26971  -6.471 5.20e-07 ***\nhp:wt        0.02785    0.00742   3.753 0.000811 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.153 on 28 degrees of freedom\nMultiple R-squared:  0.8848,\tAdjusted R-squared:  0.8724 \nF-statistic: 71.66 on 3 and 28 DF,  p-value: 2.981e-13\n```\n\n\n:::\n:::\n\n\n\n\n\n\nWhen an interaction term (e.g., horsepower \\* weight) is included in the model, the summary output provides coefficients for both main effects (horsepower and weight) as well as the interaction term. The interaction coefficient represents the change in the relationship between mpg and horsepower as weight increases.\n\n------------------------------------------------------------------------\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# do some exploratory analysis on the survey data in the MASS package\n\nlibrary(dplyr) \nsurvey \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       Sex Wr.Hnd NW.Hnd W.Hnd    Fold Pulse    Clap Exer Smoke Height      M.I\n1   Female   18.5   18.0 Right  R on L    92    Left Some Never 173.00   Metric\n2     Male   19.5   20.5  Left  R on L   104    Left None Regul 177.80 Imperial\n3     Male   18.0   13.3 Right  L on R    87 Neither None Occas     NA     <NA>\n4     Male   18.8   18.9 Right  R on L    NA Neither None Never 160.00   Metric\n5     Male   20.0   20.0 Right Neither    35   Right Some Never 165.00   Metric\n6   Female   18.0   17.7 Right  L on R    64   Right Some Never 172.72 Imperial\n7     Male   17.7   17.7 Right  L on R    83   Right Freq Never 182.88 Imperial\n8   Female   17.0   17.3 Right  R on L    74   Right Freq Never 157.00   Metric\n9     Male   20.0   19.5 Right  R on L    72   Right Some Never 175.00   Metric\n10    Male   18.5   18.5 Right  R on L    90   Right Some Never 167.00   Metric\n11  Female   17.0   17.2 Right  L on R    80   Right Freq Never 156.20 Imperial\n12    Male   21.0   21.0 Right  R on L    68    Left Freq Never     NA     <NA>\n13  Female   16.0   16.0 Right  L on R    NA   Right Some Never 155.00   Metric\n14  Female   19.5   20.2 Right  L on R    66 Neither Some Never 155.00   Metric\n15    Male   16.0   15.5 Right  R on L    60   Right Some Never     NA     <NA>\n16  Female   17.5   17.0 Right  R on L    NA   Right Freq Never 156.00   Metric\n17  Female   18.0   18.0 Right  L on R    89 Neither Freq Never 157.00   Metric\n18    Male   19.4   19.2  Left  R on L    74   Right Some Never 182.88 Imperial\n19    Male   20.5   20.5 Right  L on R    NA    Left Some Never 190.50 Imperial\n20    Male   21.0   20.9 Right  R on L    78   Right Freq Never 177.00   Metric\n21    Male   21.5   22.0 Right  R on L    72    Left Freq Never 190.50 Imperial\n22    Male   20.1   20.7 Right  L on R    72   Right Freq Never 180.34 Imperial\n23    Male   18.5   18.0 Right  L on R    64   Right Freq Never 180.34 Imperial\n24    Male   21.5   21.2 Right  R on L    62   Right Some Never 184.00   Metric\n25  Female   17.0   17.5 Right  R on L    64    Left Some Never     NA     <NA>\n26    Male   18.5   18.5 Right Neither    90 Neither Some Never     NA     <NA>\n27    Male   21.0   20.7 Right  R on L    90   Right Some Never 172.72 Imperial\n28    Male   20.8   21.4 Right  R on L    62 Neither Freq Never 175.26 Imperial\n29    Male   17.8   17.8 Right  L on R    76 Neither Freq Never     NA     <NA>\n30    Male   19.5   19.5 Right  L on R    79   Right Some Never 167.00   Metric\n31  Female   18.5   18.0 Right  R on L    76   Right None Occas     NA     <NA>\n32    Male   18.8   18.2 Right  L on R    78   Right Freq Never 180.00   Metric\n33  Female   17.1   17.5 Right  R on L    72   Right Freq Heavy 166.40 Imperial\n34    Male   20.1   20.0 Right  R on L    70   Right Some Never 180.00   Metric\n35    Male   18.0   19.0 Right  L on R    54 Neither Some Regul     NA     <NA>\n36    Male   22.2   21.0 Right  L on R    66   Right Freq Occas 190.00   Metric\n37  Female   16.0   16.5 Right  L on R    NA   Right Some Never 168.00   Metric\n38    Male   19.4   18.5 Right  R on L    72 Neither Freq Never 182.50   Metric\n39    Male   22.0   22.0 Right  R on L    80   Right Some Never 185.00   Metric\n40    Male   19.0   19.0 Right  R on L    NA Neither Freq Occas 171.00   Metric\n41  Female   17.5   16.0 Right  L on R    NA   Right Some Never 169.00   Metric\n42  Female   17.8   18.0 Right  R on L    72   Right Some Never 154.94 Imperial\n43    Male     NA     NA Right  R on L    60    <NA> Some Never 172.00   Metric\n44  Female   20.1   20.2 Right  L on R    80   Right Some Never 176.50 Imperial\n45  Female   13.0   13.0  <NA>  L on R    70    Left Freq Never 180.34 Imperial\n46    Male   17.0   17.5 Right  R on L    NA Neither Freq Never 180.34 Imperial\n47    Male   23.2   22.7 Right  L on R    84    Left Freq Regul 180.00   Metric\n48    Male   22.5   23.0 Right  R on L    96   Right None Never 170.00   Metric\n49  Female   18.0   17.6 Right  R on L    60   Right Some Occas 168.00   Metric\n50  Female   18.0   17.9 Right  R on L    50    Left None Never 165.00   Metric\n51    Male   22.0   21.5  Left  R on L    55    Left Freq Never 200.00   Metric\n52    Male   20.5   20.0 Right  L on R    68   Right Freq Never 190.00   Metric\n53    Male   17.0   18.0 Right  L on R    78    Left Some Never 170.18 Imperial\n54    Male   20.5   19.5 Right  L on R    56   Right Freq Never 179.00   Metric\n55    Male   22.5   22.5 Right  R on L    65   Right Freq Regul 182.00   Metric\n56    Male   18.5   18.5 Right  L on R    NA Neither Freq Never 171.00   Metric\n57  Female   15.5   15.4 Right  R on L    70 Neither None Never 157.48 Imperial\n58    Male   19.5   19.7 Right  R on L    72   Right Freq Never     NA     <NA>\n59    Male   19.5   19.0 Right  L on R    62   Right Freq Never 177.80 Imperial\n60    Male   20.6   21.0  Left  L on R    NA    Left Freq Occas 175.26 Imperial\n61    Male   22.8   23.2 Right  R on L    66 Neither Freq Never 187.00   Metric\n62  Female   18.5   18.2 Right  R on L    72 Neither Freq Never 167.64 Imperial\n63  Female   19.6   19.7 Right  L on R    70   Right Freq Never 178.00   Metric\n64  Female   18.7   18.0  Left  L on R    NA    Left None Never 170.00   Metric\n65  Female   17.3   18.0 Right  L on R    64 Neither Freq Never 164.00   Metric\n66    Male   19.5   19.8 Right Neither    NA   Right Freq Never 183.00   Metric\n67  Female   19.0   19.1 Right  L on R    NA Neither Freq Never 172.00   Metric\n68  Female   18.5   18.0 Right  R on L    64   Right Freq Never     NA     <NA>\n69    Male   19.0   19.0 Right  L on R    NA   Right Some Never 180.00   Metric\n70    Male   21.0   19.5 Right  L on R    80    Left None  <NA>     NA     <NA>\n71  Female   18.0   17.5 Right  L on R    64    Left Freq Never 170.00   Metric\n72    Male   19.4   19.5 Right  R on L    NA   Right Freq Heavy 176.00   Metric\n73  Female   17.0   16.6 Right  R on L    68   Right Some Never 171.00   Metric\n74  Female   16.5   17.0 Right  L on R    40    Left Freq Never 167.64 Imperial\n75  Female   15.6   15.8 Right  R on L    88    Left Some Never 165.00   Metric\n76  Female   17.5   17.5 Right Neither    68   Right Freq Heavy 170.00   Metric\n77  Female   17.0   17.6 Right  L on R    76   Right Some Never 165.00   Metric\n78  Female   18.6   18.0 Right  L on R    NA Neither Freq Heavy 165.10 Imperial\n79  Female   18.3   18.5 Right  R on L    68 Neither Some Never 165.10 Imperial\n80    Male   20.0   20.5 Right  L on R    NA   Right Freq Never 185.42 Imperial\n81    Male   19.5   19.5  Left  R on L    66    Left Some Never     NA     <NA>\n82    Male   19.2   18.9 Right  R on L    76   Right Freq Never 176.50 Imperial\n83  Female   17.5   17.5 Right  R on L    98    Left Freq Never     NA     <NA>\n84  Female   17.0   17.4 Right  R on L    NA Neither Some Never     NA     <NA>\n85    Male   23.0   23.5 Right  L on R    90   Right Freq Never 167.64 Imperial\n86  Female   17.7   17.0 Right  R on L    76   Right Some Never 167.00   Metric\n87  Female   18.2   18.0 Right  L on R    70   Right Some Never 162.56 Imperial\n88  Female   18.3   18.5 Right  R on L    75    Left Freq Never 170.00   Metric\n89    Male   18.0   18.0 Right Neither    60   Right Freq Never 179.00   Metric\n90  Female   18.0   17.7  Left  R on L    92    Left Some Never     NA     <NA>\n91    Male   20.5   20.0 Right  R on L    75    Left Some Never 183.00   Metric\n92  Female   17.5   18.0 Right Neither    NA   Right Some Never     NA     <NA>\n93  Female   18.2   17.5 Right  L on R    70   Right Some Never 165.00   Metric\n94  Female   18.2   18.5 Right  R on L    NA   Right Some Never 168.00   Metric\n95    Male   21.3   20.8 Right  R on L    65   Right Freq Heavy 179.00   Metric\n96  Female   19.0   18.8 Right  L on R    NA   Right Some Never     NA     <NA>\n97    Male   20.0   19.5 Right  R on L    68 Neither Freq Regul 190.00   Metric\n98  Female   17.5   17.5 Right  R on L    60   Right Freq Never 166.50   Metric\n99    Male   19.5   19.4 Right Neither    NA   Right Freq Never 165.00   Metric\n100 Female   19.4   19.6 Right  R on L    68 Neither Freq Never 175.26 Imperial\n101   Male   21.9   22.2 Right  R on L    NA   Right Some Never 187.00   Metric\n102   Male   18.9   19.1 Right  L on R    60 Neither None Never 170.00   Metric\n103 Female   16.0   16.0 Right Neither    NA   Right Some Never 159.00   Metric\n104 Female   17.5   17.3 Right  R on L    72   Right Freq Never 175.00   Metric\n105 Female   17.5   17.0 Right  R on L    80    Left Some Heavy 163.00   Metric\n106 Female   19.5   18.5 Right  R on L    80   Right Some Never 170.00   Metric\n107 Female   16.2   16.4 Right  R on L    NA   Right Freq Occas 172.00   Metric\n108 Female   17.0   15.9 Right  R on L    85   Right Freq Never     NA     <NA>\n109   Male   17.5   17.5 Right  L on R    64 Neither Freq Never 180.00   Metric\n110   Male   19.7   20.1 Right  R on L    67    Left Some Regul 180.34 Imperial\n111 Female   18.5   18.5 Right  R on L    76    Left Freq Never 175.00   Metric\n112   Male   19.2   19.6 Right  L on R    80   Right None Never 190.50 Imperial\n113 Female   17.2   16.7 Right  R on L    75   Right Freq Never 170.18 Imperial\n114   Male   20.5   21.0 Right  R on L    60   Right Freq Never 185.00   Metric\n115 Female   16.0   15.5 Right  L on R    60    Left Freq Never 162.56 Imperial\n116 Female   16.9   16.0 Right  L on R    70   Right None Never 158.00   Metric\n117 Female   17.0   16.7 Right  R on L    70   Right Some Never 159.00   Metric\n118   Male   23.0   22.0  Left  L on R    83    Left Some Heavy 193.04 Imperial\n119 Female   18.5   18.0  Left  L on R   100 Neither Some Never 171.00   Metric\n120   Male   21.0   20.4 Right  L on R   100   Right Freq Heavy 184.00   Metric\n121   Male   20.0   20.0 Right  R on L    80 Neither Freq Occas     NA     <NA>\n122   Male   22.5   22.5 Right  L on R    76   Right Freq Occas 177.00   Metric\n123 Female   18.5   18.0 Right  R on L    92   Right Freq Never 172.00   Metric\n124   Male   19.8   20.0  Left  L on R    59   Right Freq Never 180.00   Metric\n125   Male   18.5   18.1 Right  L on R    66    Left Freq Never 175.26 Imperial\n126   Male   19.3   19.4 Right  R on L    NA   Right Freq Never 180.34 Imperial\n127 Female   16.0   16.0 Right  R on L    68   Right Freq Never 172.72 Imperial\n128   Male   18.8   19.1 Right  L on R    66 Neither Freq Regul 178.50   Metric\n129 Female   17.5   17.0 Right  R on L    74   Right Freq Never 157.00   Metric\n130 Female   16.4   16.5 Right  L on R    90   Right Some Never 152.00   Metric\n131   Male   22.0   21.5 Right  R on L    86   Right Freq Never 187.96 Imperial\n132   Male   19.0   19.5 Right  L on R    60   Right Some Never 178.00   Metric\n133 Female   18.9   20.0 Right  R on L    86   Right Some Never     NA     <NA>\n134 Female   15.4   16.4  Left  L on R    80    Left Freq Occas 160.02 Imperial\n135   Male   17.9   17.8 Right  R on L    85    Left Some Never 175.26 Imperial\n136   Male   23.1   22.5 Right  L on R    90   Right Some Regul 189.00   Metric\n137   <NA>   19.8   19.0  Left  L on R    73 Neither Freq Never 172.00   Metric\n138   Male   22.0   22.0 Right  L on R    72   Right Freq Never 182.88 Imperial\n139   Male   20.0   19.5 Right  L on R    NA   Right Freq Never 170.00   Metric\n140 Female   19.5   18.5 Right  L on R    68   Right None Never 167.00   Metric\n141 Female   18.0   18.6 Right  R on L    84   Right Some Never 175.00   Metric\n142 Female   18.3   19.0 Right  R on L    NA   Right None Never 165.00   Metric\n143 Female   19.0   18.8 Right  R on L    65   Right Freq Never 172.72 Imperial\n144   Male   21.4   21.0 Right  L on R    96 Neither Some Never 180.00   Metric\n145 Female   20.0   19.5  Left  R on L    68 Neither Freq Never 172.00   Metric\n146   Male   18.5   18.5 Right  R on L    75 Neither Some Never 185.00   Metric\n147   Male   22.5   22.6 Right  L on R    64   Right Freq Regul 187.96 Imperial\n148   Male   19.5   20.2 Right  R on L    60 Neither Freq Never 185.42 Imperial\n149 Female   18.0   18.0 Right  L on R    92 Neither Freq Never 165.00   Metric\n150 Female   18.0   18.5 Right  R on L    64 Neither Freq Never 164.00   Metric\n151   Male   21.8   22.3 Right  R on L    76    Left Freq Never 195.00   Metric\n152 Female   13.0   12.5 Right  L on R    80   Right Freq Never 165.00   Metric\n153 Female   16.3   16.2 Right  L on R    92   Right Some Regul 152.40 Imperial\n154   Male   21.5   21.6 Right  R on L    69   Right Freq Never 172.72 Imperial\n155   Male   18.9   19.1 Right  L on R    68   Right None Never 180.34 Imperial\n156   Male   20.5   20.0 Right  R on L    76   Right Freq Never 173.00   Metric\n157   Male   14.0   15.5 Right  L on R    NA Neither Freq Heavy     NA     <NA>\n158 Female   18.9   19.2 Right  L on R    74   Right Some Never 167.64 Imperial\n159   Male   20.0   20.5 Right  R on L    NA   Right None Never 187.96 Imperial\n160   Male   18.5   19.0 Right  L on R    84   Right Freq Regul 187.00   Metric\n161 Female   17.5   17.1 Right  R on L    80    Left None Never 167.00   Metric\n162   Male   18.1   18.2  Left Neither    NA   Right Some Never 168.00   Metric\n163   Male   20.2   20.3 Right  L on R    72 Neither Some Never 191.80 Imperial\n164 Female   16.5   16.9 Right  R on L    60 Neither Freq Occas 169.20   Metric\n165   Male   19.1   19.1 Right Neither    NA   Right Some Never 177.00   Metric\n166 Female   17.6   17.2 Right  R on L    81    Left Some Never 168.00   Metric\n167 Female   19.5   19.2 Right  R on L    70   Right Some Never 170.00   Metric\n168 Female   16.5   15.0 Right  L on R    65   Right Some Regul 160.02 Imperial\n169   Male   19.0   18.5 Right  L on R    NA Neither Freq Never 189.00   Metric\n170   Male   19.0   18.5 Right  R on L    72   Right Freq Never 180.34 Imperial\n171 Female   16.5   17.0 Right  L on R    NA   Right Some Never 168.00   Metric\n172   Male   20.5   19.5  Left  L on R    80   Right Some Occas 182.88 Imperial\n173 Female   15.5   15.5 Right Neither    50   Right Some Regul     NA     <NA>\n174 Female   18.0   17.5 Right  R on L    48 Neither Freq Never 165.00   Metric\n175 Female   17.5   18.0 Right  R on L    68 Neither Freq Never 157.48 Imperial\n176 Female   19.0   18.5  Left  L on R   104    Left Freq Never 170.00   Metric\n177   Male   20.5   20.5 Right Neither    76   Right Freq Regul 172.72 Imperial\n178 Female   16.7   17.0 Right  L on R    84    Left Freq Never 164.00   Metric\n179 Female   20.5   20.5 Right  R on L    NA    Left Freq Regul     NA     <NA>\n180 Female   17.0   16.5 Right  R on L    70   Right Some Never 162.56 Imperial\n181   Male   19.0   19.5 Right  R on L    68   Right Freq Occas 172.00   Metric\n182 Female   14.0   13.5 Right  R on L    87 Neither Freq Occas 165.10 Imperial\n183 Female   17.5   17.6 Right  L on R    79   Right Some Never 162.50   Metric\n184   Male   18.5   19.0 Right  L on R    70    Left Freq Never 170.00   Metric\n185   Male   18.0   18.5 Right Neither    90   Right Some Never 175.00   Metric\n186   Male   20.5   20.7 Right  R on L    72   Right Some Never 168.00   Metric\n187 Female   17.0   17.0 Right  L on R    79   Right Some Never 163.00   Metric\n188   Male   18.5   18.5 Right  R on L    65   Right None Never 165.00   Metric\n189   Male   18.0   18.5 Right  R on L    62   Right Freq Never 173.00   Metric\n190   Male   18.5   18.0 Right Neither    63 Neither Freq Never 196.00   Metric\n191   Male   20.0   19.5 Right  R on L    92   Right Some Never 179.10 Imperial\n192   Male   22.0   22.5 Right  L on R    60   Right Some Never 180.00   Metric\n193   Male   17.9   18.4 Right  R on L    68    Left None Occas 176.00   Metric\n194 Female   17.6   17.8 Right  L on R    72    Left Some Never 160.02 Imperial\n195 Female   16.7   15.1 Right Neither    NA   Right None Never 157.48 Imperial\n196 Female   17.0   17.6 Right  L on R    76   Right Some Never 165.00   Metric\n197 Female   15.0   13.0 Right  R on L    80 Neither Freq Never 170.18 Imperial\n198   Male   16.0   15.5 Right Neither    71   Right Freq Never 154.94 Imperial\n199 Female   19.1   19.0 Right  R on L    80   Right Some Occas 170.00   Metric\n200 Female   17.5   16.5 Right  R on L    80 Neither Some Never 164.00   Metric\n201 Female   16.2   15.8 Right  R on L    61   Right Some Occas 167.00   Metric\n202   Male   21.0   21.0 Right  L on R    48 Neither Freq Never 174.00   Metric\n203 Female   18.8   17.8 Right  R on L    76   Right Some Never     NA     <NA>\n204 Female   18.5   18.0 Right Neither    86   Right None Never 160.00   Metric\n205   Male   17.0   17.5 Right  R on L    80   Right Some Regul 179.10   Metric\n206 Female   17.5   17.0 Right  R on L    83 Neither Freq Occas 168.00   Metric\n207 Female   17.5   17.6 Right  L on R    76   Right Some Never 153.50   Metric\n208   Male   17.5   17.6 Right  R on L    84   Right Some Never 160.00   Metric\n209   Male   17.5   17.0  Left  L on R    97 Neither None Never 165.00   Metric\n210 Female   20.8   20.7 Right  R on L    NA Neither Freq Never 171.50   Metric\n211 Female   18.6   18.6 Right  L on R    74   Right Some Never 160.00   Metric\n212 Female   17.5   17.5  Left  R on L    83 Neither Some Never 163.00   Metric\n213   Male   18.0   18.5 Right  R on L    78   Right Freq Never     NA     <NA>\n214   Male   17.0   17.5 Right  R on L    65   Right Some Never 165.00   Metric\n215 Female   18.0   17.8 Right  L on R    68   Right Some Never 168.90 Imperial\n216   Male   19.5   20.0 Right Neither    NA   Right Some Never 170.00   Metric\n217 Female   16.3   16.2 Right  L on R    NA   Right None Never     NA     <NA>\n218   Male   18.2   19.8 Right  R on L    88   Right Freq Never 185.00   Metric\n219 Female   17.0   17.3 Right  L on R    NA Neither Freq Never 173.00   Metric\n220   Male   23.2   23.2 Right  L on R    75   Right Freq Never 188.00   Metric\n221   Male   23.2   23.3 Right  L on R    NA   Right None Heavy 171.00   Metric\n222 Female   15.9   16.5 Right  R on L    70   Right Freq Never 167.64 Imperial\n223 Female   17.5   18.4 Right  R on L    88   Right Some Never 162.56 Imperial\n224 Female   17.5   17.6 Right  L on R    NA   Right Freq Never 150.00   Metric\n225 Female   17.6   17.2 Right  L on R    NA   Right Some Never     NA     <NA>\n226 Female   17.5   17.8 Right  R on L    96   Right Some Never     NA     <NA>\n227 Female   18.8   18.3 Right  R on L    80   Right Some Heavy 170.18 Imperial\n228   Male   20.0   19.8 Right  L on R    68   Right Freq Never 185.00   Metric\n229 Female   18.6   18.8 Right  L on R    70   Right Freq Regul 167.00   Metric\n230   Male   18.6   19.6 Right  L on R    71   Right Freq Occas 185.00   Metric\n231 Female   18.8   18.5 Right  R on L    80   Right Some Never 169.00   Metric\n232   Male   18.0   16.0 Right  R on L    NA   Right Some Never 180.34 Imperial\n233 Female   18.0   18.0 Right  L on R    85   Right Some Never 165.10 Imperial\n234 Female   18.5   18.0 Right  L on R    88   Right Some Never 160.00   Metric\n235 Female   17.5   16.5 Right  R on L    NA   Right Some Never 170.00   Metric\n236   Male   21.0   21.5 Right  R on L    90   Right Some Never 183.00   Metric\n237 Female   17.6   17.3 Right  R on L    85   Right Freq Never 168.50   Metric\n       Age\n1   18.250\n2   17.583\n3   16.917\n4   20.333\n5   23.667\n6   21.000\n7   18.833\n8   35.833\n9   19.000\n10  22.333\n11  28.500\n12  18.250\n13  18.750\n14  17.500\n15  17.167\n16  17.167\n17  19.333\n18  18.333\n19  19.750\n20  17.917\n21  17.917\n22  18.167\n23  17.833\n24  18.250\n25  19.167\n26  17.583\n27  17.500\n28  18.083\n29  21.917\n30  19.250\n31  41.583\n32  17.500\n33  39.750\n34  17.167\n35  17.750\n36  18.000\n37  19.000\n38  17.917\n39  35.500\n40  19.917\n41  17.500\n42  17.083\n43  28.583\n44  17.500\n45  17.417\n46  18.500\n47  18.917\n48  19.417\n49  18.417\n50  30.750\n51  18.500\n52  17.500\n53  18.333\n54  17.417\n55  20.000\n56  18.333\n57  17.167\n58  17.417\n59  17.667\n60  18.417\n61  20.333\n62  17.333\n63  17.500\n64  19.833\n65  18.583\n66  18.000\n67  30.667\n68  16.917\n69  19.917\n70  18.333\n71  17.583\n72  17.833\n73  17.667\n74  17.417\n75  17.750\n76  20.667\n77  23.583\n78  17.167\n79  17.083\n80  18.750\n81  16.750\n82  20.167\n83  17.667\n84  17.167\n85  17.167\n86  17.250\n87  18.000\n88  18.750\n89  21.583\n90  17.583\n91  19.667\n92  18.000\n93  19.667\n94  17.083\n95  22.833\n96  17.083\n97  19.417\n98  23.250\n99  18.083\n100 19.083\n101 18.917\n102 17.750\n103 20.833\n104 20.167\n105 17.667\n106 18.250\n107 17.000\n108 18.500\n109 18.583\n110 17.750\n111 24.167\n112 18.167\n113 21.167\n114 17.917\n115 17.417\n116 20.500\n117 22.917\n118 18.917\n119 18.917\n120 20.083\n121 17.500\n122 18.250\n123 17.500\n124 17.417\n125 21.000\n126 19.833\n127 17.667\n128 18.083\n129 18.000\n130 18.333\n131 20.000\n132 18.750\n133 19.083\n134 18.500\n135 18.417\n136 19.167\n137 21.500\n138 19.333\n139 21.417\n140 18.667\n141 17.500\n142 21.083\n143 17.250\n144 19.000\n145 19.167\n146 19.000\n147 23.000\n148 32.667\n149 20.000\n150 20.167\n151 25.500\n152 18.167\n153 23.500\n154 70.417\n155 43.833\n156 23.583\n157 21.083\n158 44.250\n159 19.667\n160 17.917\n161 18.417\n162 21.167\n163 17.500\n164 29.083\n165 19.917\n166 18.500\n167 18.167\n168 32.750\n169 17.417\n170 17.333\n171 73.000\n172 18.667\n173 18.500\n174 18.667\n175 17.750\n176 17.250\n177 36.583\n178 23.083\n179 19.250\n180 17.167\n181 23.417\n182 17.083\n183 17.250\n184 23.833\n185 18.750\n186 21.167\n187 24.667\n188 18.500\n189 20.333\n190 20.083\n191 18.917\n192 27.333\n193 18.917\n194 17.250\n195 18.167\n196 26.500\n197 17.000\n198 17.167\n199 19.167\n200 17.500\n201 19.250\n202 21.333\n203 18.583\n204 20.167\n205 18.667\n206 17.083\n207 17.417\n208 18.583\n209 19.500\n210 18.500\n211 17.167\n212 17.250\n213 17.500\n214 20.417\n215 17.083\n216 21.250\n217 19.250\n218 19.333\n219 19.167\n220 18.917\n221 20.917\n222 17.333\n223 18.167\n224 20.750\n225 19.917\n226 18.667\n227 18.417\n228 17.417\n229 20.333\n230 19.333\n231 18.167\n232 20.750\n233 17.667\n234 16.917\n235 18.583\n236 17.167\n237 17.750\n```\n\n\n:::\n\n```{.r .cell-code}\nsurvey <- as_tibble(survey)\n\n# check the structure of the data\n\nstr(survey) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntibble [237 × 12] (S3: tbl_df/tbl/data.frame)\n $ Sex   : Factor w/ 2 levels \"Female\",\"Male\": 1 2 2 2 2 1 2 1 2 2 ...\n $ Wr.Hnd: num [1:237] 18.5 19.5 18 18.8 20 18 17.7 17 20 18.5 ...\n $ NW.Hnd: num [1:237] 18 20.5 13.3 18.9 20 17.7 17.7 17.3 19.5 18.5 ...\n $ W.Hnd : Factor w/ 2 levels \"Left\",\"Right\": 2 1 2 2 2 2 2 2 2 2 ...\n $ Fold  : Factor w/ 3 levels \"L on R\",\"Neither\",..: 3 3 1 3 2 1 1 3 3 3 ...\n $ Pulse : int [1:237] 92 104 87 NA 35 64 83 74 72 90 ...\n $ Clap  : Factor w/ 3 levels \"Left\",\"Neither\",..: 1 1 2 2 3 3 3 3 3 3 ...\n $ Exer  : Factor w/ 3 levels \"Freq\",\"None\",..: 3 2 2 2 3 3 1 1 3 3 ...\n $ Smoke : Factor w/ 4 levels \"Heavy\",\"Never\",..: 2 4 3 2 2 2 2 2 2 2 ...\n $ Height: num [1:237] 173 178 NA 160 165 ...\n $ M.I   : Factor w/ 2 levels \"Imperial\",\"Metric\": 2 1 NA 2 2 1 1 2 2 2 ...\n $ Age   : num [1:237] 18.2 17.6 16.9 20.3 23.7 ...\n```\n\n\n:::\n\n```{.r .cell-code}\npairs(survey)\n```\n\n::: {.cell-output-display}\n![](week14_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# subset the data\n\nsurvey %>% \n  select(Wr.Hnd, NW.Hnd, Pulse, Height, Age) -> df1 \ndf1 \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 237 × 5\n   Wr.Hnd NW.Hnd Pulse Height   Age\n    <dbl>  <dbl> <int>  <dbl> <dbl>\n 1   18.5   18      92   173   18.2\n 2   19.5   20.5   104   178.  17.6\n 3   18     13.3    87    NA   16.9\n 4   18.8   18.9    NA   160   20.3\n 5   20     20      35   165   23.7\n 6   18     17.7    64   173.  21  \n 7   17.7   17.7    83   183.  18.8\n 8   17     17.3    74   157   35.8\n 9   20     19.5    72   175   19  \n10   18.5   18.5    90   167   22.3\n# ℹ 227 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\npairs(df1)\n```\n\n::: {.cell-output-display}\n![](week14_files/figure-html/unnamed-chunk-25-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# build our model with one indicator\n\nmlm1 <- lm(cbind(df1$Height, df1$Pulse) ~ df1$Age) \n\nmlm1 <- lm(cbind(Height, Pulse) ~ Age, data = df1) \n\nsummary(mlm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nResponse Height :\n\nCall:\nlm(formula = Height ~ Age, data = df1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-20.608  -7.528  -1.583   7.379  27.399 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 173.39245    2.66936  64.957   <2e-16 ***\nAge          -0.04278    0.12503  -0.342    0.733    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.916 on 169 degrees of freedom\n  (66 observations deleted due to missingness)\nMultiple R-squared:  0.0006923,\tAdjusted R-squared:  -0.005221 \nF-statistic: 0.1171 on 1 and 169 DF,  p-value: 0.7327\n\n\nResponse Pulse :\n\nCall:\nlm(formula = Pulse ~ Age, data = df1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-38.130  -7.160  -0.721   6.360  29.381 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  78.9229     3.0761  25.657   <2e-16 ***\nAge          -0.2448     0.1441  -1.699   0.0912 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.43 on 169 degrees of freedom\n  (66 observations deleted due to missingness)\nMultiple R-squared:  0.01679,\tAdjusted R-squared:  0.01097 \nF-statistic: 2.886 on 1 and 169 DF,  p-value: 0.09118\n```\n\n\n:::\n\n```{.r .cell-code}\n# build our model with more than one indicator\n\nmlm2 <- lm(cbind(Height, Pulse) ~ Age + Wr.Hnd + NW.Hnd, data = df1) \n\nsummary(mlm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nResponse Height :\n\nCall:\nlm(formula = Height ~ Age + Wr.Hnd + NW.Hnd, data = df1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-20.5028  -4.9668  -0.9197   4.3439  25.6729 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 115.8383     5.9953  19.322   <2e-16 ***\nAge          -0.1341     0.1004  -1.337   0.1832    \nWr.Hnd        2.7889     1.2009   2.322   0.0214 *  \nNW.Hnd        0.3776     1.1727   0.322   0.7478    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.823 on 166 degrees of freedom\n  (67 observations deleted due to missingness)\nMultiple R-squared:  0.389,\tAdjusted R-squared:  0.378 \nF-statistic: 35.23 on 3 and 166 DF,  p-value: < 2.2e-16\n\n\nResponse Pulse :\n\nCall:\nlm(formula = Pulse ~ Age + Wr.Hnd + NW.Hnd, data = df1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-38.244  -6.902  -0.928   6.238  29.893 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  78.3243     8.8045   8.896 9.54e-16 ***\nAge          -0.2242     0.1474  -1.521    0.130    \nWr.Hnd        0.5060     1.7636   0.287    0.775    \nNW.Hnd       -0.4947     1.7221  -0.287    0.774    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.49 on 166 degrees of freedom\n  (67 observations deleted due to missingness)\nMultiple R-squared:  0.01518,\tAdjusted R-squared:  -0.002614 \nF-statistic: 0.8531 on 3 and 166 DF,  p-value: 0.4668\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(resid(mlm1)) # residuals \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       Height      Pulse\n1   0.3883076  17.544343\n2   5.1597724  29.381073\n5  -7.3799460 -38.129668\n6   0.2259562  -9.782504\n7  10.2932491   8.687051\n8 -14.8594685   3.848360\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(fitted(mlm1)) # estimates fitted for the model\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Height    Pulse\n1 172.6117 74.45566\n2 172.6402 74.61893\n5 172.3799 73.12967\n6 172.4940 73.78250\n7 172.5868 74.31295\n8 171.8595 70.15164\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(resid(mlm2)) # residuals \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      Height      Pulse\n1   1.217489  17.311649\n2   2.195023  29.893015\n5 -10.994527 -38.243539\n6   2.814107  -9.967349\n7  13.520106   8.698683\n8  -7.976292   3.665699\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(fitted(mlm2)) # estimates fitted for the model\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Height    Pulse\n1 171.7825 74.68835\n2 175.6050 74.10699\n5 175.9945 73.24354\n6 169.9059 73.96735\n7 169.3599 74.30132\n8 164.9763 70.33430\n```\n\n\n:::\n\n```{.r .cell-code}\n# gather coefficients\n\ncoef(mlm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 Height      Pulse\n(Intercept) 115.8382861 78.3242718\nAge          -0.1341361 -0.2241610\nWr.Hnd        2.7889054  0.5059615\nNW.Hnd        0.3776366 -0.4947372\n```\n\n\n:::\n\n```{.r .cell-code}\n# variance-covariance matrix\n\nvcov(mlm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                   Height:(Intercept)   Height:Age Height:Wr.Hnd Height:NW.Hnd\nHeight:(Intercept)        35.94337245 -0.154686949  -1.874139393   0.147649352\nHeight:Age                -0.15468695  0.010072486   0.012318156  -0.015095498\nHeight:Wr.Hnd             -1.87413939  0.012318156   1.442122756  -1.361112632\nHeight:NW.Hnd              0.14764935 -0.015095498  -1.361112632   1.375140647\nPulse:(Intercept)         -6.06537128  0.026103109   0.316257226  -0.024915529\nPulse:Age                  0.02610311 -0.001699712  -0.002078664   0.002547335\nPulse:Wr.Hnd               0.31625723 -0.002078664  -0.243355293   0.229684999\nPulse:NW.Hnd              -0.02491553  0.002547335   0.229684999  -0.232052198\n                   Pulse:(Intercept)    Pulse:Age Pulse:Wr.Hnd Pulse:NW.Hnd\nHeight:(Intercept)       -6.06537128  0.026103109  0.316257226 -0.024915529\nHeight:Age                0.02610311 -0.001699712 -0.002078664  0.002547335\nHeight:Wr.Hnd             0.31625723 -0.002078664 -0.243355293  0.229684999\nHeight:NW.Hnd            -0.02491553  0.002547335  0.229684999 -0.232052198\nPulse:(Intercept)        77.51891942 -0.333612690 -4.041948507  0.318434733\nPulse:Age                -0.33361269  0.021723288  0.026566515 -0.032556397\nPulse:Wr.Hnd             -4.04194851  0.026566515  3.110220051 -2.935505860\nPulse:NW.Hnd              0.31843473 -0.032556397 -2.935505860  2.965760021\n```\n\n\n:::\n:::\n",
    "supporting": [
      "week14_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}