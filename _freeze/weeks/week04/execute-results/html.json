{
  "hash": "e25f9609579c1bb88d67701d98580e74",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"DATA 202 - Week 4\"\nsubtitle: \"Probability Theory\"\nauthor: \"Nathan Alexander, PhD\"\ninstitute: \"Center for Applied Data Science and Analytics\"\nformat: \n  html: default\n  revealjs:\n    output-file: week04-slides.html\n    height: 900\n    width: 1600\n    smaller: false\n    scrollable: true\n    slide-number: c/t #< collapsted/total\n    logo: \"img/howard-logo.jpg\"\n    footer: \"[Course Data GitHub](https://github.com/data-202)\"\n    toc: false\n    echo: true\n    incremental: false\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n# Part I: Context\n\n------------------------------------------------------------------------\n\n## More on theory construction\n\nLast week, we considered one cyclical process of theory construction.\n\n![Theory construction. Image from saylordotorg.github.io](img/wk3-e-0.jpg){width=\"40%\"}\n\n------------------------------------------------------------------------\n\nThis week, we return to this idea of theory construction but with more detail.\n\n::: incremental\n-   Research inquiry\n\n-   Hypotheses\n\n-   Analysis\n\n-   Evaluation\n\n-   Revision\n:::\n\n------------------------------------------------------------------------\n\n::: incremental\n-   **Research inquiry**\n\n    -- Transfer your reading and informal observations into pratical problems\n\n-   **Hypotheses**\n\n    -- Utilize the research literature to understand your research problem\n\n    -- Extend this research literature by developing your own research questions\n\n    -- Based on your research question(s), develop a hypothesis (or a set of hypotheses)\n\n-   **Analysis**\n\n    -- Outline your empirical study in specific details to conduct your analysis\n\n    -- Conduct your analysis and <u> consider the limitations of your methods </u>\n\n-   **Evaluation**\n\n    -- Evaluate your analytic findings alongside your hypotheses\n\n-   **Revision**\n\n    -- Utilize the reseaerch literature to revise or confirm your hypotheses\n:::\n\n------------------------------------------------------------------------\n\n### Limitations\n\nAcross research methodologies, a *limitation* is any feature of a study that may cause concerns. Limitations vary in both their scope and context. As a result, it is important to consider both the obvious limitations and hidden concerns.\n\n-   Some examples of limitations in statistics\n\n::: incremental\n```         \n- Lack of reliable data\n\n- Limited sample size\n\n- Deficiencies in measurements of data\n```\n:::\n\n-   Not limitations but \"bad\" statistical practices\n\n::: incremental\n```         \n- Theory does not depict the entire story or phenomenon\n\n- Old data (and research citations)\n\n- Broad conclusions with no supporting data\n\n- Analyzing data for significant results. P-hacking!\n```\n:::\n\n------------------------------------------------------------------------\n\n### Developing a logic model\n\nLogic is an important component in theory construction. **Logical reasoning** is the use of critical thinking in the applications of statistics, and relates to our forthcoming focus on probability. However, *logic* in relation to theory is based on a set of ideas that help build sound and consistent arguments that can be analyzed, measured, and support model construction and development.\n\nA few key considerations:\n\n::: incremental\n-   **Premises and conclusions**\n\n    -- Clear statements are used; statements are focused and direct\n\n-   **Internal structure**\n\n    -- There is consistency in your premises and any conclusions\n\n    -- There are no contradictions in your structure\n\n-   **Arguments and inferences**\n\n    -- Your argument follow your initial premises, internal structure, and conclusions\n:::\n\n------------------------------------------------------------------------\n\n### Path diagrams\n\nOne way to visualize the relationships between your variables is in a **path diagram**.\n\n-   Path diagrams are used in *path analysis*, a subset of statistical methods that help researchers discern and assess the relationship(s) between multiple variables.\n\n-   Path analysis is based on a closed system of nested relationships.\n\n    -- These nested relationships must have a logical internal structure.\n\n-   Together, a path diagram can represent a series of structured linear regression equations.\n\n-   Path models are often used in economics and political science.\n\nAs we move further into our analyses, we will learn more about path analysis.\n\n------------------------------------------------------------------------\n\nThis is a simple two-variable path diagram\n\n\n\n\n\n\n```{mermaid}\n%%| echo: false\n%%| fig-responsive: false\n%%| fig-width: 10\nflowchart LR\n  A[X] --> B[Y]\n```\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n### Exercise\n\nIdentify two variables for a simple path diagram.\n\n$X$ (independent variable) and $Y$ (dependent variable)\n\n-   What is the logical relationship between the variables?\n\n    -- Write a logical statement.\n\n-   What is the question that structures the relationship between the variables?\n\n    -- Turn your logic statement into a question.\n\n-   What is your theory on how the two variables relate to one another?\n\n    -- Write a theoretical statement based on the research literature.\n\n-   What is your hypothesis?\n\n    -- Develop an educated guess based on the research literature.\n\n------------------------------------------------------------------------\n\nThree variable path diagram\n\n\n\n\n\n\n```{mermaid}\n%%| echo: false\n%%| fig-responsive: false\n%%| fig-width: 10\nflowchart LR\n  A[Variable 1] --> B[Y]\n  C[Variable 2] --> B\n```\n\n\n\n\n\n\nA path diagram made of multiple variables\n\n\n\n\n\n\n```{mermaid}\n%%| echo: false\n%%| fig-responsive: false\n%%| fig-width: 10\nflowchart LR\n  A[Variable 1] --> B[Y]\n  C[Variable 2] --> B\n  D[Variable 3] --> B\n```\n\n\n\n\n\n\n# Part II: Content\n\n------------------------------------------------------------------------\n\nOur main goal for content this week will be to better frame and understand the relationship between mathematics and statistics through the lens of probability theory. These concepts are closely related but differ in both their forms and functions.\n\n::: incremental\n-   Understand the role of mathematics in modern statistics\n\n-   Distinguish between algebra and statistics\n\n-   Identify basic mathematical terms useful for statistical analysis\n:::\n\n------------------------------------------------------------------------\n\n#### <u>Objective 1</u>: Frame the role of probability in statistics\n\nProbability theory forms the backbone of statistical inference and modeling.\n\nKey Concepts\n\n-   **Probability Space**: A probability space is a mathematical construct that contains the results of a random process, generally known as an experiment. The probability space consists of:\n\n    -   Sample space ($\\Omega$): The set of all possible outcomes\n\n    -   Event space ($F$): A collection of subsets of $\\Omega$ containing the various events, $E$\n\n    -   Probability measure ($P$): A function assigning probabilities to events\n\nClassic example: Tossing a fair coin\n\n-   $\\Omega = \\{Heads, Tails\\}$\n\n-   $F$ = {∅, {Heads}, {Tails}, {Heads, Tails}}\n\n-   $P({Heads}) = P({Tails}) = 0.5$, $P(∅) = 0$, $P({Heads, Tails}) = 1$\n\n------------------------------------------------------------------------\n\n-   \\*Random Variables\\*\\*: Random variables (RVs) are functions mapping the sample space to real numbers. We generally study:\n\n    -   Discrete random variables: Take on countable values\n\n    -   Continuous random variables: Take on uncountable values\n\n    -   Probability mass function (PMF): $P(X = x)$ for discrete RVs\n\n    -   Probability density function (PDF): $f(x)$ for continuous RVs\n\n    -   Cumulative distribution function (CDF): $F(x) = P(X \\leq x)$\n\n------------------------------------------------------------------------\n\n-   *Expectation and Moments*\n\n    -   Expected value: $E[X] = ∑xP(X=x)$ or $∫xf(x) dx$\n\n    -   Variance: Var(X) = $E[(X - E[X])^2]$\n\n    -   Standard deviation: $\\sigma = \\sqrt{Var(X)}$\n\n    -   Higher-order moments: $E[X^n]$\n\n    -   Moment generating function: $M_X(t) = E[e^(tX)]$\n\nClassic example: Standard normal distribution $N(0, 1)$ i.e., where $0$ is the mean, $\\mu$, and $1$ is the variance, $\\sigma^2$.\n\n-   $E[X] = 0$\n\n-   $Var(X) = 1$\n\n-   Recall, the Standard normal distribution:\n\n    It's symmetric around the mean of 0; it's bell-shaped curve has a peak at x = 0.\n\n    -   \\~68% of the data falls within one standard deviation of the mean (between -1 and 1).\n\n    -   \\~95% of the data falls within two standard deviations of the mean (between -2 and 2).\n\n    -   \\~99.7% of the data falls within three standard deviations of the mean (between -3 and 3).\n\n------------------------------------------------------------------------\n\n#### <u>Objective 3</u>: Distinguish between algebra and statistics\n\n::: incremental\nAt its core, statistics is a branch of applied mathematics.\n\n-   Statistics developed from various abstract concepts in mathematics\n\n    -- Many of these concepts were applications of probability theory, which is more abstract.\n\n-   We refer to statistics as an *applied* mathematical tool.\n\n-   We refer to algebra as a *pure* mathematical tool.\n\n-   The differences between pure and applied mathematics can be described in many ways.\n\n    -- However, applied mathematics most often relates to applications in the real world and pure mathematics focuses on abstraction.\n:::\n\n------------------------------------------------------------------------\n\nThe table below presents one example on the difference in how mathematics is used in algebra versus statistics.\n\nWe use our knowledge of algebra to build our understanding of statistics.\n\n| In algebra | In statistics           |\n|------------|-------------------------|\n| $y=mx + b$ | $y_i=a+bx_i+\\epsilon_i$ |\n\nGenerally, in the algebra equations, we model \"exactness.\" In statistical models, we produce estimates.\n\n------------------------------------------------------------------------\n\n#### <u>Objective 4</u>: Identify basic mathematical terms useful for statistical analysis\n\nToday we will consider three terms:\n\n::: incremental\n-   Scientific notation\n\n-   Subscripts\n\n-   Summation notation\n:::\n\n------------------------------------------------------------------------\n\n**Scientific notation**.\n\nCalculators have a limited number of spaces to report values.\n\n-   In your calculator, you may have noticed a value containing a capital **E**\n\n    -   Some examples are 2.35E4 or 2.35E-4.\n\n-   This is *scientific notation*.\n\n-   The method is instructing you to move the decimal point a certain number of spaces:\n\n    -- To the right: 2.35E4 is really 2.35 x $10^{4}$, or 23,500\n\n    -- To the left: 2.35E-4 is really 2.35 x $10^{-4}$, or 0.000235\n\n------------------------------------------------------------------------\n\n**Subscripts**.\n\nWe use an \"$i$\" to refer to a subscript and to index the position of a value in our data set.\n\n-   $x_i$ refers to the i-th entry of a data set, $X$.\n\n-   If there are multiple variables (columns) in our data set, say a first variable $X$ and a second variable is $Y$, we say that $x_i$ refers to the i-th entry for variable $X$ and $y_i$ refers to the i-th entry of variable $Y$.\n\n    -- To do so, we can make use the set of numbers (such as the whole numbers $\\mathbb{Z}^+$ or the positive integers $\\mathbb{Z}^{+}$) that we reviewed in class.\n\n    -- If a data set $X$ contains three values such that $X = \\{9, 5, 12\\}$, these values can be denoted using subscripts as: $x_1 = 9$, $x_2= 5$, $x_3 = 12$.\n\n------------------------------------------------------------------------\n\n#### Indexing elements of a data set\n\nIn the table below, we can see how subscripts are used to denote the elements of a data set.\n\n| $X$   | $Y$   |\n|-------|-------|\n| $x_1$ | $y_1$ |\n| $x_2$ | $y_2$ |\n| $x_3$ | $y_3$ |\n| .     | .     |\n| .     | .     |\n| .     | .     |\n| $x_n$ | $y_n$ |\n\n------------------------------------------------------------------------\n\n**Summation notation**.\n\nIn mathematics, the Greek letter $\\Sigma$ (Sigma) is reserved for summation (addition)\n\n-   We may need to sum values or numbers in a data set.\n\n-- For example, the notation: $$\\sum_{i=1}^{n} x_i $$ is used to indicate that we need to add up all of the values (up to $n$) for our variable $X$.\n\n------------------------------------------------------------------------\n\nIf we have a total of five rows in our data set, such that $n=5$ (here $n \\in \\mathbb{N}$), then we write:\n\n$$\\sum_{i=1}^{5} x_i = x_1 + x_2 + x_3 + x_4 + x_5$$\n\n------------------------------------------------------------------------\n\nIf we wanted to square our values before adding them up, we would write: $$\\sum_{i=1}^{n} (x_i)^2 $$ This would result in the following expansion if we let $n=5$ with $n \\in \\mathbb{N}$,$$\\sum_{i=1}^{5} (x_i)^2 = (x_1)^2 + (x_2)^2 + (x_3)^2 + (x_4)^2 + (x_5)^2$$\n\n------------------------------------------------------------------------\n\n#### Rows and columns\n\n**Rows**. A *row* in a data set is generally used to refer to individual **observations**.\n\n**Columns**. A *column* in a data set is generally used to refer to individual **variables**.\n\n------------------------------------------------------------------------\n\n### Databases\n\nLast week, we created a small data set called a data frame. This week, we'll briefly introduce databases for later.\n\nDatabases are collections of data sets or multiple data frames.\n\nFor example, a set of state records can be stored by year, or the same information can be restructured into a set of sets defined by state. In either case, we will define the elements of a *database as a set of k sets* where each set is a data set. As before, we index items in a set using a lower case $i$ and start with 1 such that $i = 1, 2, 3, ...,k-1, k$ (note the use of $k$ instead of $n$).\n\n------------------------------------------------------------------------\n\n::: {.callout-caution icon=\"false\"}\n## **DEFINITION**: DATABASE\n\nA **database**, $D$, is a well-defined set of $k$ data sets (or dataframes) that includes algorithms and other components to perform operations on a data set, a set, or some cross section. $$ D = \\{ d_1, d_2, d_3, ..., d_{k-1}, d_k \\} $$\n:::\n\nAgain, take note that we change the index from an $n$ to $k$; we do this to avoid confusion.\n\n------------------------------------------------------------------------\n\n::: {.callout-tip icon=\"false\"}\n## **EXERCISE -- Hillman College Electronic Database**\n\nHillman College maintains data on all enrolled students in an electronic database. The database is structured into a series of data sets that are defined by year. If the college has kept a single data set for each year since it's founding in 1875, how many data sets are in the database? That is, what is the value of $k$ for the database? **Hint: Consider the index**.\n:::\n\n------------------------------------------------------------------------\n\n![A database containing k datasets](img/wk3-e-5.jpg)\n\nIn the first example, we can consider a \"small\" example to help us answer the question. Take only the first few data sets of the database. For example, assume we start collecting data in the current year (year 1) and do so for the following two years:\n\nLet $d_1$ correspond to this year, $d_2$ correspond to next year, and $d_3$ correspond to the year after.\n\nNote, however, when we rush to subtract the index on the last data set, $d_3$ from the first data set $d_1$, we end up with a value of 2. However, we see that there are, in fact, a total of three (3) data sets in the database: this year's data set, next year's data set, and the year after next year's data set. This is due to the method we use to index a database.\n\n------------------------------------------------------------------------\n\n# Part III: Code\n\nThis week, we will prepare for Lab 1.\n\n#### Task 0.1: Check your working directory\n\nIn your console, type in the following code to ensure you are in the desired directory:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngetwd()\n```\n:::\n\n\n\n\n\n\nIf you are not in the desired directory, you can change your directory using the associated path. This path should be the same as the project folder that you plan to work out of for our course.\n\nFor example, `stats/lab1`\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# insert your desired path in the parenthesis and remove the #\n# setwd(\"/your/working/directory/goes/here\") \n```\n:::\n\n\n\n\n\n\nYou can also add a sub-folder manually or under the **Files** tab in the RStudio IDE.\n\n#### Task 0.2: Start a new RMarkdown\n\nOnce you have confirmed that you are in the correct directory, start a new RMarkdown file.\n\n## Task 1: Open a RMarkdown file\n\nPrior to conducting any analyses in R, we want to include a brief summary of our work so that we (and others who read our code) know what we are prioritizing. This is an important step to documenting our research. We will write this *preamble* at the very top of our RMarkdown file.\n\nA *preamble* is simply an introduction to your code. The structure of a preamble can vary widely. In an RMarkdown file, we can use hashtags (#) to write certain sections in our preamble. The \\# symbol informs R that it should ignore that line in our code.\n\n```         \n---\ntitle: \"Lab No. #\"\nauthor: \n  - name: \"Insert Your Name\"\n    affiliation: \"DATA 202, Fall 2024, Howard University\"\ndate: \"2024-08-15\"\nalways_allow_html: true\noutput: \n  html_document:\n    toc: true\n    toc_depth: 2\n    number_sections: true\n    self_contained: yes\n    mode: selfcontained\n  pdf_document:\n    toc: true\n    toc_depth: 2\n    number_sections: true\ngeometry: margin=1.0in\n---\n```\n\nLet's head over to Lab 1 to continue.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}